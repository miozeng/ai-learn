{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 训练/验证(开发)/测试集;\n",
    "\n",
    "一般地，我们将所有的样本数据分成三个部分：训练/验证（开发）/测试集。训练集用来训练算法模型；开发集用来验证算法的表现；测试集用来测试算法的实际表现，作为该算法的无偏估计。\n",
    "\n",
    "    1）、机器学习中，由于样本量小（例如：10000个样本），通常设置训练/验证/测试集的比例为：60%、20%、20% 或者 70%、30%、0% 较为合理。\n",
    "    2）、深度学习中，由于样本量超大（例如：10 000 000个样本），通常设置训练/验证/测试集的比例为：98%、1%、1% 或者 99%、0.5%、0.5%较为合理。\n",
    "\n",
    "在深度学习中，务必保障训练集/验证集/测试集来自于同一数据分布。\n",
    "\n",
    "如果没有测试集也是可以的。测试集的主要目标是进行无偏估计。我们可以通过训练集训练不同的算法模型，然后分别在验证集上进行验证，根据结果选择最好的算法模型。\n",
    "\n",
    "使用验证集评估训练集的效果。然后，在模型“通过”验证集之后，使用测试集再次检查评估结果。\n",
    "\n",
    "在这一经过改进的工作流程中：\n",
    "\n",
    "    1.选择在验证集上获得最佳效果的模型。\n",
    "    2.使用测试集再次检查该模型。\n",
    "该工作流程之所以更好，原因在于它暴露给测试集的信息更少。\n",
    "\n",
    "不断使用测试集和验证集会使其逐渐失去效果。也就是说，您使用相同数据来决定超参数设置或其他模型改进的次数越多，您对于这些结果能够真正泛化到未见过的新数据的信心就越低。请注意，验证集的失效速度通常比测试集缓慢。\n",
    "如果可能的话，建议您收集更多数据来“刷新”测试集和验证集。重新开始是一种很好的重置方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 偏差/方差;\n",
    "在机器学习算法中，偏差和方差对应着欠拟合和过拟合，是对立的，我们常常需要在偏差和方差之间进行权衡。\n",
    "而在深度学习中，我们可以同时减小偏差和方差，构建最佳神经网络模型。\n",
    "在深度学习中，我们可以通过两个数值：训练集error和开发集error来理解偏差和方差。\n",
    "\n",
    "    1）训练集error为1%，而开发集error为6%，说明该模型对训练样本可能存在过拟合，模型泛化能力不强，是高方差（high variable）的表现；\n",
    "    2）训练集error为5%，而开发集error为6%，说明该模型对训练样本存在欠拟合，是高偏差（high bias）的表现；\n",
    "    3）训练集error为5%，而开发集 error为10%，说明模型既存在高偏差也存在高方差（可以理解成部分欠拟合，部分过拟合）；\n",
    "    4）假设训练集error为0.5%，而开发error为1%，即低偏差和低方差，是最理想的情况。\n",
    "深度学习中最重要的一个问题就是避免出现高偏差和高方差。\n",
    "\n",
    "    1）减少高偏差的常用方法是增加神经网络的隐层数、神经元数，延长训练时间，增加模型复杂度等。\n",
    "    2）减少高方差的常用方法是重新清洗数据，增加训练样本量，加大正则化程度，增加模型复杂度等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1解决高方差/高偏差\n",
    "1.是否存在High bias ? \n",
    "\n",
    "    增加网络结构，如增加隐藏层数目；\n",
    "    训练更长时间；\n",
    "    寻找合适的网络架构，使用更大的NN结构；\n",
    "\n",
    "2.是否存在High variance？ \n",
    "\n",
    "    获取更多的数据；\n",
    "    正则化（ regularization）；\n",
    "    寻找合适的网络结构；\n",
    "\n",
    "在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以使得再不增加另一方的情况下减少一方的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 正则化;\n",
    "\n",
    "#### 3.1 L2正则化（（权重衰减））\n",
    "\n",
    "范数\n",
    "范数是衡量某个向量空间（或矩阵）中的每个向量以长度或大小。范数的一般化定义：对实数p>=1， 范数定义如下：(Σ|x|**p)**(1/p)\n",
    "\n",
    "    L1范数\n",
    "    当p=1时，是L1范数，其表示某个向量中所有元素绝对值的和。\n",
    "    L2范数\n",
    "    当p=2时，是L2范数， 表示某个向量中所有元素平方和再开根， 也就是欧几里得距离公式。\n",
    "    \n",
    "利用正则化来解决 High variance 高方差的问题，正则化是在 Cost function 中加入一项正则化项，调整模型的复杂度。\n",
    "\n",
    "Logistic regression\n",
    "加入正则化项的代价函数：\n",
    "\n",
    "    L2正则化：(λ/2m)*W.T * W \n",
    "    其中 λ 为正则化因子（参数）。\n",
    "    注意：lambda 在python中属于保留字，所以在编程的时候，用“lambd”代表这里的正则化因子 λ。\n",
    "\n",
    "Neural network 神经网络中加入 L2 正则\n",
    "加入正则化项的代价函数：\n",
    "\n",
    "    1/m*Σl(y,yhat)+(λ/2m)*W.T * W \n",
    "\n",
    "权重衰减（Weight decay）\n",
    "在加入正则化项后，梯度变为：\n",
    "\n",
    "    W=W-α*dJ(W)/dW）-α(λ/m)*W= (1-αλ/m)*W-α*dJ(W)/dW）\n",
    "    \n",
    "其中 1-αλ/m)<1的项，会给原来的W一个衰减的参数，所以 L2 范数正则化也被称为“权重衰减（Weight decay）”。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 为什么正则化可以减少过拟合？\n",
    "加入正则化项，直观上理解，正则化因子λ设置的足够大的情况下，为了使代价函数最小化，权重矩阵 W 就会被设置为接近于 0 的值。则相当于消除了很多神经元的影响，那么图中的大的神经网络就会变成一个较小的网络。\n",
    "当然上面这种解释是一种直观上的理解，但是实际上隐藏层的神经元依然存在，但是他们的影响变小了，便不会导致过拟合。\n",
    "\n",
    "数学解释：\n",
    "\n",
    "假设神经元中使用的激活函数为 g(z)=tanh(z)，在加入正则化项后：\n",
    "\n",
    "当λ增大，导致W减小，Z 便会减小，在z较小的区域里，tanh⁡(z)函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，从而不会发生过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3 dropout\n",
    "Dropout（随机失活）就是在神经网络的Dropout层，为每个神经元结点设置一个随机消除的概率，对于保留下来的神经元，我们得到一个节点较少，规模较小的网络进行训练。\n",
    "\n",
    "这里我们以单个神经元入手，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了 Dropout 以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。要选择的参数是 keep-prob ，它代表每一层上保留单元的概率，每一层不同。所以通过传播过程，dropout 将产生和 L2 范数相同的收缩权重的效果。\n",
    "\n",
    "对于不同的层，设置的keep_prob也不同，一般来说神经元较少的层，会设 keep_prob =1.0，神经元多的层，则会将keep_prob设置的较小。\n",
    "计算视觉中的输入量非常大，输入了太多像素 ，没有足够的数据，所以 dropout 在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它\n",
    "\n",
    "dropout 是一种正则化方法，它有助于预防过拟合，除非算法过拟合，否则不要使用 dropout 。\n",
    "缺点：\n",
    "dropout 的一大缺点就是其使得 Cost function不能再被明确的定义，以为每次迭代都会随机消除一些神经元结点，所以我们无法绘制出每次迭代 J(W,b)下降的图\n",
    "\n",
    "首先假设对 layer 3 进行dropout：\n",
    "\n",
    "    keep_prob = 0.8  # 设置神经元保留概率\n",
    "    d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep_prob\n",
    "    a3 = np.multiply(a3, d3)\n",
    "    a3 /= keep_prob\n",
    "\n",
    "依照例子中的 keep_prob = 0.8，那么就有大约 20% 的神经元被删除了，也就是说 a[3] 中有 20% 的元素被归零了，在下一层的计算中有图片: Z[4]=W[4]⋅a[3]+b[4]，所以为了不影响 Z[4] 的期望值，所以需要 W[4]⋅a[3]的部分除以一个 keep_prob。也就是保留下的值，在某种程度上增大了。\n",
    "Inverted dropout 是通过对“a3 /= keep_prob”,则保证无论 keep_prob 设置为多少，都不会对 Z[4]的期望值产生影响。\n",
    "\n",
    "需要注意的是，训练阶段才会使用dropout，测试和实际应用阶段不能进行dropout。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 其他正则化方法\n",
    "数据扩增（Data augmentation）：通过图片的一些变换，得到更多的训练集和验证集；。\n",
    "\n",
    "Early stopping：在交叉验证集（dev set）的误差上升之前的点停止迭代，避免过拟合。这种方法的缺点是无法同时解决 bias 和 variance 之间的最优。 \n",
    "\n",
    "运行梯度下降时，可以绘制训练误差，或只绘制代价函数 J 的优化过程，在训练集上用 0-1 记录分类误差次数，呈单调下降趋势。(train set)\n",
    "\n",
    "还可以绘制验证集误差，它可以是验证集上的分类误差，或验证集上的代价函数 逻辑损失和对数损失等.(dev set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4归一化输入\n",
    "之所以要对输入进行标准化操作，主要是为了让所有输入归一化同样的尺度上，方便进行梯度下降算法时能够更快更准确地找到全局最优解。\n",
    "　\n",
    " 归一化输入需要两个步骤，第一步是零均值化，即每个元素减去均值操作\n",
    " \n",
    "     μ= (1/m)*Σx\n",
    "     x=x-u\n",
    "\n",
    " \n",
    " 第二步是，归一化方差\n",
    " \n",
    "     δ**2 = 1/m*Σx*x\n",
    "     x=x/δ**2\n",
    " \n",
    " 由于训练集进行了标准化处理，那么对于测试集或在实际应用时，应该使用同样的和对其进行标准化处理。这样保证了训练集合测试集的标准化操作一致。\n",
    " \n",
    "在不使用归一化的代价函数中，如果我们设置一个较小的学习率，那么很可能我们需要很多次迭代才能到达代价函数全局最优解；\n",
    "如果使用了归一化，那么无论从哪个位置开始迭代，我们都能以相对很少的迭代次数找到全局最优解。代价函数平均起来看更对称。\n",
    "所以如果输入特征处于不同范围内，可能有些特征值从 0 到 1 有些从 1 到 1000，那么归一化特征值就非常重要。\n",
    "执行这类归一化并不会产生什么危害，Andrew Ng 经常会做归一化处理，即使不确定它能否提高训练或算法速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5梯度消失与爆炸\n",
    "训练神经网络尤其是深度神经网络所面临的一个问题是，梯度消失或梯度爆炸，也就是说 当你训练深度网络时，导数或坡度有时会变得非常大，或非常小 甚至以指数方式变小， 加大了训练难度。\n",
    "\n",
    "上面的情况对于导数也是同样的道理，所以在计算梯度时，根据情况的不同，梯度函数会以指数级递增或者递减，导致训练导数难度上升，梯度下降算法的步长会变得非常非常小，需要训练的时间将会非常长。\n",
    "\n",
    "在梯度函数上出现的以指数级递增或者递减的情况就分别称为梯度爆炸或者梯度消失。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.1利用初始化缓解梯度消失和爆炸问题\n",
    "改善梯度消失或梯度爆炸的方法是：对权重w进行一些初始化处理。\n",
    "深度神经网络模型中，以单个神经元为例。\n",
    "当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。\n",
    "\n",
    "对参数进行初始化：\n",
    "\n",
    "   WL = np.random.randn(WL.shape[0],WL.shape[1])* np.sqrt(1/n)\n",
    "\n",
    "这么做是因为，如果激活函数的输入 x 近似设置成均值为 0，标准方差 1 的情况，输出 z 也会调整到相似的范围内。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.2梯度检验\n",
    "因为我们的神经网络中含有大量的参数：W[1],b[1],⋯,W[L],b[L]，为了做梯度检验，需要将这些参数全部连接起来，reshape成一个大的向量 θ。\n",
    "同时对 dW[1],db[1],⋯,dW[L],db[L]执行同样的操作，dθ。\n",
    "判断dθapprox≈dθ是否接近。\n",
    "公式：\n",
    "\n",
    "    ||dθapprox-dθ||2/（||dθapprox||+||dθ||）\n",
    "其中，“||⋅||2”表示欧几里得范数，它是误差平方之和，然后求平方根，得到的欧氏距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.3Notes\n",
    "    不要在训练过程中使用梯度检验，只在debug的时候使用，使用完毕关闭梯度检验的功能；\n",
    "    如果算法的梯度检验出现了错误，要检查每一项，找出错误，也就是说要找出哪个dθapprox[i]与dθ的值相差比较大；\n",
    "    不要忘记了正则化项；\n",
    "    梯度检验不能与dropout同时使用。因为每次迭代的过程中，dropout会随机消除隐层单元的不同神经元，这时是难以计算dropout在梯度下降上的代价函数J；\n",
    "    在随机初始化的时候运行梯度检验，或许在训练几次后再进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.Mini-batch 梯度下降法\n",
    "我们可以利用一个巨大的数据集来训练神经网络，而在巨大的数据集基础上进行训练速度很慢，因此，你会发现使用快速的优化算法，使用好用的优化算法能够，大大提高你和团队的效率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1不同下降法比较\n",
    "batch梯度下降：\n",
    "\n",
    "    batch 的大小 = m，对所有 m 个训练样本执行一次梯度下降，（一次处理 m 个）每一次迭代时间较长；\n",
    "    Cost function 总是向减小的方向下降。\n",
    "    优点：全局最优解；易于并行实现； \n",
    "    缺点：当样本数目很多时，训练过程会很慢。 \n",
    "\n",
    "随机梯度下降：\n",
    "\n",
    "    随机梯度下降就是每次从所有训练样例中抽取一个样本进行更新，这样每次都不用遍历所有数据集，迭代速度会很快，但是会增加很多迭代次数，因为每次选取的方向不一定是最优的方向.\n",
    "    Cost function 总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。\n",
    "\n",
    "Mini-batch梯度下降：\n",
    "\n",
    "    这是介于以上两种方法的折中，每次随机选取大小为b的mini-batch(b<m), b通常取10，或者(2...100),这样既节省了计算整个批量的时间，同时用mini-batch计算的方向也会更加准确。\n",
    "    选择一个1<size<m的合适的 size 进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处。\n",
    "    Cost function 的下降处于前两者之间。\n",
    "    得到了大量向量化，不需要等待整个训练集被处理完，就可以开始进行后续工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 6.2Mini-batch 大小的选择\n",
    "\n",
    "在合理范围内，增大 Batch_Size 有何好处？\n",
    "\n",
    "    内存利用率提高了，大矩阵乘法的并行化效率提高。\n",
    "    跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。\n",
    "    在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。\n",
    "\n",
    "盲目增大 Batch_Size 有何坏处？\n",
    "\n",
    "    内存利用率提高了，但是内存容量可能撑不住了。\n",
    "    跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。\n",
    "    Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。\n",
    "\n",
    "\n",
    "如果训练样本的大小比较小时，如 m⩽ 2000 时 —— 选择 batch 梯度下降法；\n",
    "\n",
    "mini-batch 大小参数通常设置为 64, 128,  256, 512。考虑到电脑内存的设置和使用方式mini-batch 大小的大小通常设置为2的次方，代码会运行的快一些\n",
    "Mini-batch 的大小要符合 CPU/GPU 内存。\n",
    "\n",
    "个人理解：一开始使用向量化一次处理 m 个，太大了，时间太长，那就处理的稍微小点，但是也绝不可以一次处理一个，那向量化摆着不用干嘛，所以最后要 找一个 1 < size < m,这就是传说中的 mini-batch 了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.指数加权平均\n",
    "指数加权平均(exponentially weighted averges)，也叫指数加权移动平均，是一种常用的序列数据处理方式。\n",
    "\n",
    "移动指数加权平均法加权就是根据同一个移动段内不同时间的数据对预测值的影响程度，分别给予不同的权数，然后再进行平均移动以预测未来值。假定给定一系列数据值x1, x2,x3,……xn。那么，我们根据这些数据来拟合一条曲线，所得的值v1, v2…..就是如下的公式： \n",
    "\n",
    "    v[t] =βv[t-1] +(1-β)x[t]\n",
    "指数加权平均数公式好处，只占用极少内存，电脑内存中只占一行数字，然后把最新数据代入公式，不断覆盖。\n",
    "因为，在计算当前时刻的平均值，只需要前一天的平均值和当前时刻的值，所以在数据量非常大的情况下，指数加权平均在节约计算成本的方面是一种非常有效的方式，可以很大程度上减少计算机资源存储和内存的占用。\n",
    "\n",
    "指数加权平均，作为原数据的估计值，不仅可以 1. 抚平短期波动，起到了平滑的作用，2. 还能够将长线趋势或周期趋势显现出来。\n",
    "所以应用比较广泛，在处理统计数据时，在股价等时间序列数据中，CTR 预估中，美团外卖的收入监控报警系统中的 hot-winter 异常点平滑，深度学习的优化算\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 7.1β的选择\n",
    "    β 越小，噪音越多，虽然能够很快的适应温度的变化，但是更容易出现奇异值。\n",
    "    β 越大，得到的曲线越平坦，因为多平均了几天的温度，这个曲线的波动更小。\n",
    "    但有个缺点是，因为只有 0.02 的权重给了当天的值，而之前的数值权重占了 0.98 ，\n",
    "    曲线进一步右移，在温度变化时就会适应地更缓慢一些，会出现一定延迟。\n",
    "    通过上面的内容可知，β 也是一个很重要的超参数，不同的值有不同的效果，需要调节来达到最佳效果，一般 0.9 的效果就很好。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 7.2动量梯度下降法\n",
    "动量梯度下降的基本思想就是计算梯度的指数加权平均数，并利用该梯度来更新权重。运行速度几乎总是快于标准的梯度下降算法。\n",
    "\n",
    "    Vdw =βVdw +(1-β)dw\n",
    "    Vdb =βVdb +(1-β)db\n",
    "\n",
    "    W:= W-αVdw \n",
    "    b:= b-αVdb \n",
    "\n",
    "其中，在上面的公式中vdw和vdb分别是损失函数在前t−1轮迭代过程中累积的梯度梯度动量\n",
    "在我们进行动量梯度下降算法的时候，由于使用了指数加权平均的方法。原来在纵轴方向上的上下波动，经过平均以后，接近于0（1-β），纵轴上的波动变得非常的小；但在横轴方向上，所有的微分都指向横轴方向，因此其平均值仍然很大。最终实现红色线所示的梯度下降曲线。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.3RMSprop\n",
    "为了进一步优化损失函数在更新中存在摆动幅度过大的问题，并且进一步加快函数的收敛速度，RMSProp算法对权重 W 和偏置 b 的梯度使用了微分平方加权平均数。 \n",
    "其中，假设在第 t 轮迭代过程中，各个公式如下所示：\n",
    "\n",
    "    Sdw =βSdw +(1-β)dw**2\n",
    "    Sdb =βSdb +(1-β)db**2\n",
    "\n",
    "    W:= W-α(dw /(Sdw**1/2+ε))\n",
    "    b:= b-α(db /(Sdb**1/2+ε))\n",
    "算法的主要思想就用上面的公式表达完毕了。在上面的公式中sdw和sdb分别是损失函数在前t−1轮迭代过程中累积的梯度梯度动量，β 是梯度累积的一个指数。所不同的是，RMSProp算法对梯度计算了微分平方加权平均数。然后使用平方根进行梯度更新，这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快。同时为了确保算法不会除以 0，平方根分母中在实际使用会加入一个很小的值如 ε=10**-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.4Adam 优化算法\n",
    "Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.学习率衰减\n",
    "在我们利用 mini-batch 梯度下降法来寻找 Cost function 的最小值的时候，如果我们设置一个固定的学习速率 α，则算法在到达最小值点附近后，由于不同 batch 中存在一定的噪声，使得不会精确收敛，而一直会在一个最小值点较大的范围内波动，如下图中蓝色线所示。\n",
    "加快学习算法的一个办法就是，随时间慢慢减少学习率，我们将之称为学习率衰减。\n",
    "但是如果我们使用学习率衰减，逐渐减小学习速率 α，在算法开始的时候，学习速率还是相对较快，能够相对快速的向最小值点的方向下降。但随着α的减小，下降的步伐也会逐渐变小，最终会在最小值附近的一块更小的区域里波动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.超参数的选择\n",
    "#### 9.1为超参数选择合适的范围\n",
    "在超参数选择的时候，一些超参数是在一个范围内进行均匀随机取值，如隐藏层神经元结点的个数、隐藏层的层数等。但是有一些超参数的选择做均匀随机取值是不合适的，这里需要按照一定的比例在不同的小范围内进行均匀随机取值，以学习率α的选择为例，如果在 0.001,…,1 的范围内进行进行均匀随机取值，则有90%的概率 选择范围在 0.1∼1 之间，而只有10%的概率才能选择到0.001∼0.1之间，显然是不合理的。\n",
    "所以在选择的时候，在不同比例范围内进行均匀随机取值，如0.001∼0.001、0.001∼0.01、0.01∼0.1、0.1∼1 范围内选择。\n",
    "\n",
    "#### 9.2超参数训练的实践\n",
    "Pandas（一个模型不同的超参数） VS Caviar（多个模型多个超参数）\n",
    "\n",
    "在超参数调试的实际操作中，我们需要根据我们现有的计算资源来决定以什么样的方式去调试超参数，进而对模型进行改进。下面是不同情况下的两种方式：\n",
    "\n",
    "    在计算资源有限的情况下，使用Pandas，仅调试一个模型，每天不断优化；\n",
    "    在计算资源充足的情况下，使用Caviar，同时并行调试多个模型，选取其中最好的模型。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Batch Norm \n",
    "#### 10.1网络中激活值的归一化\n",
    "在 logistic Regression 中，将输入特征进行归一化，可以加速模型的训练。那么对于更深层次的神经网络，我们是否可以归一化隐藏层的输出a[l]或者经过激活函数前的z[l]，以便加速神经网络的训练过程？答案是肯定的。\n",
    "常用的方式是将隐藏层的经过激活函数前的z[l]进行归一化。\n",
    "\n",
    "    μ = 1/m Σz[i]\n",
    "    δ**2 = 1/m Σ(z[i]-μ)**2\n",
    "    z[i]norm =(z[i]-μ)/(δ**2+ ε)**0.5\n",
    "这里加上 ε 是为了保证数值的稳定。\n",
    "\n",
    "到这里所有 z 的分量都是平均值为 0 和方差为 1 的分布，但是我们不希望隐藏层的单元总是如此，也许不同的分布会更有意义，所以我们再进行计算：\n",
    "\n",
    "    z~[i] =γz[i]norm +β\n",
    "这里 γ和 β是可以更新学习的参数，如神经网络的权重w一样，两个参数的值来确定z~[i]  所属的分布。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 神经网络中融入Batch Norm \n",
    "BN的基本思想其实相当直观：因为深层神经网络在做非线性变换前的激活输入值（就是那个y=Wx+B，U是输入）随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于Sigmoid函数来说，意味着激活输入值=Wx+B是大的负值或正值），所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因，而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。\n",
    "\n",
    "在神经网络中融入Batch Norm\n",
    "在深度神经网络中应用 Batch Norm，这里以一个简单的神经网络为例，\n",
    " 计算神经网络一般分为两步，计算Z和a,而BN是发生在Z和a之间的\n",
    "\n",
    "实现梯度下降 \n",
    "\n",
    "for t = 1 … num （这里 num 为 Mini Batch 的数量）： \n",
    "\n",
    "   在每一个 x[t]的计算： \n",
    "      在每个隐藏层都用 Batch Norm 将 z[l] 替换成 z~[l]\n",
    "\n",
    "使用反向传播（Back prop）计算各个参数的梯度：dw[l] dγ[l] dβ[l]\n",
    "\n",
    "更新参数： \n",
    " \n",
    "    w[l] = w[l] -αdw[l]\n",
    "    γ[l] = γ[l] -αdγ[l]\n",
    "    w[l] = ββ[l] -αdβ[l]\n",
    "    \n",
    "同样与 Mini-batch 梯度下降法相同，Batch Norm 同样适用于 momentum、RMSprop、Adam 的梯度下降法来进行参数更新。\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3Batch Norm 起作用的原因\n",
    "\n",
    "首先 Batch Norm 可以加速神经网络训练的原因和输入层的输入特征进行归一化，从而改变 Cost function 的形状，使得每一次梯度下降都可以更快的接近函数的最小值点，从而加速模型训练过程的原理是有相同的道理。\n",
    "只是 Batch Norm 不是单纯的将输入的特征进行归一化，而是将各个隐藏层的激活函数的激活值进行的归一化，并调整到另外的分布。\n",
    "\n",
    "然后Batch Norm 可以加速神经网络训练的另外一个原因是它可以使权重比网络更滞后或者更深层。\n",
    "\n",
    "Batch Norm 削弱了前层参数与后层参数之间的联系，使得网络的每层都可以自己进行学习，相对其他层有一定的独立性，这会有助于加速整个网络的学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 10.4Batch Norm 正则化效果\n",
    "Batch Norm还有轻微的正则化效果。\n",
    "这是因为在使用 Mini-batch 梯度下降的时候，每次计算均值和偏差都是在一个 Mini-batch 上进行计算，而不是在整个数据样集上。这样就在均值和偏差上带来一些比较小的噪声。那么用均值和偏差计算得到的 z˜[l]也将会加入一定的噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
