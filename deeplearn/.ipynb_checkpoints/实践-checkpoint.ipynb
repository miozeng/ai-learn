{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "testdata = pd.read_csv('../data/dataannalysis/happiness_test_abbr.csv')\n",
    "traindata = pd.read_csv('../data/dataannalysis/happiness_train_abbr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#异常数据处理\n",
    "traindata = traindata[traindata['happiness'] != -8]\n",
    "traindata = traindata[traindata['depression'] != -8]\n",
    "traindata = traindata[traindata['class'] != -8]\n",
    "traindata = traindata[traindata['health'] != -8]\n",
    "traindata = traindata[traindata['equity'] != -8]\n",
    "traindata = traindata[traindata['family_status'] != -8]\n",
    "traindata = traindata[traindata['health_problem'] != -8]\n",
    "traindata = traindata[traindata['relax'] != -8]\n",
    "traindata = traindata[traindata['learn'] != -8]\n",
    "traindata['view'].replace(-8,3,inplace = True)\n",
    "traindata = traindata[traindata['socialize'] != -8]\n",
    "traindata = traindata[traindata['socialize'] != -1]\n",
    "traindata = traindata[traindata['socialize'] != -2]\n",
    "traindata = traindata[traindata['socialize'] != -3]\n",
    "traindata = traindata[traindata['socialize'] != 50]\n",
    "traindata = traindata[traindata['status_3_before'] != -8]\n",
    "traindata = traindata[traindata['status_peer'] != -8]\n",
    "traindata['inc_ability'].replace(-8,3,inplace = True)\n",
    "\n",
    "#数据重新处理\n",
    "traindata['marital'].replace(2,1,inplace = True)\n",
    "traindata['marital'].replace(3,1,inplace = True)\n",
    "traindata['marital'].replace(4,1,inplace = True)\n",
    "traindata['marital'].replace(7,1,inplace = True)\n",
    "traindata['marital'].replace(6,2,inplace = True)\n",
    "traindata['marital'].replace(5,3,inplace = True)\n",
    "\n",
    "bins = [-100,0,100000,300000,500000,1000000,10000000] \n",
    "traindata['income'] = pd.cut(traindata['income'],bins, labels=['1','2', '3', '4', '5', '6'])\n",
    "\n",
    "\n",
    "\n",
    "avg_income=traindata['family_income']/traindata['family_m']\n",
    "traindata['avg_income'] = avg_income\n",
    "bins = [-100,0,20000,50000,100000,1000000,10000000] \n",
    "traindata['avg_income'] = pd.cut(traindata['avg_income'],bins, labels=['1','2', '3', '4', '5', '6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata['avg_income'].('unknown', inplace=True)\n",
    "traindata['avg_income'] = traindata['avg_income'].cat.add_categories(['0']);\n",
    "traindata['avg_income'].fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder() \n",
    "le.fit(['1','2', '3', '4', '5', '6', '0']) \n",
    "traindata['avg_income']  = le.transform(traindata['avg_income'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder() \n",
    "le.fit(['1','2', '3', '4', '5', '6']) \n",
    "traindata['income']  = le.transform(traindata['income'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0.008267\n",
       "happiness          1.000000\n",
       "survey_type       -0.035656\n",
       "province          -0.021285\n",
       "city              -0.023442\n",
       "county            -0.021499\n",
       "gender             0.018517\n",
       "birth             -0.004821\n",
       "nationality       -0.035595\n",
       "religion           0.006780\n",
       "religion_freq      0.010455\n",
       "edu                0.104231\n",
       "income             0.043733\n",
       "political          0.080010\n",
       "floor_area         0.044722\n",
       "height_cm          0.040638\n",
       "weight_jin         0.084260\n",
       "health             0.246918\n",
       "health_problem     0.212923\n",
       "depression         0.320490\n",
       "hukou              0.079546\n",
       "socialize          0.079689\n",
       "relax              0.123843\n",
       "learn              0.123454\n",
       "equity             0.284537\n",
       "class              0.301481\n",
       "work_exper         0.008198\n",
       "work_status       -0.039226\n",
       "work_yr           -0.018063\n",
       "work_type          0.021679\n",
       "work_manage       -0.039622\n",
       "family_income      0.052113\n",
       "family_m           0.059978\n",
       "family_status      0.306640\n",
       "house              0.092656\n",
       "car               -0.110458\n",
       "marital           -0.077905\n",
       "status_peer       -0.273150\n",
       "status_3_before   -0.177749\n",
       "view               0.133684\n",
       "inc_ability       -0.191048\n",
       "avg_income         0.102122\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重新做相关性分析\n",
    "traindata.corr()['happiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatafinal = traindata[['happiness','depression','class','health','equity','family_status','health_problem','relax','learn','view','socialize','status_peer','status_3_before','inc_ability','car','avg_income','edu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = traindatafinal[:7000]\n",
    "test_data = traindatafinal[7000:]\n",
    " \n",
    "train_data_X = train_data.drop(['happiness'],axis=1)\n",
    "train_data_Y = train_data['happiness']\n",
    "test_data_X = test_data.drop(['happiness'],axis=1)\n",
    "test_data_Y = test_data['happiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depression</th>\n",
       "      <th>class</th>\n",
       "      <th>health</th>\n",
       "      <th>equity</th>\n",
       "      <th>family_status</th>\n",
       "      <th>health_problem</th>\n",
       "      <th>relax</th>\n",
       "      <th>learn</th>\n",
       "      <th>view</th>\n",
       "      <th>socialize</th>\n",
       "      <th>status_peer</th>\n",
       "      <th>status_3_before</th>\n",
       "      <th>inc_ability</th>\n",
       "      <th>car</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depression  class  health  equity  family_status  health_problem  relax  \\\n",
       "0           5      3       3       3              2               2      4   \n",
       "1           3      6       5       3              4               4      4   \n",
       "2           5      5       4       4              3               4      4   \n",
       "3           4      5       4       4              3               4      4   \n",
       "4           3      1       5       2              3               5      3   \n",
       "\n",
       "   learn  view  socialize  status_peer  status_3_before  inc_ability  car  \\\n",
       "0      3     4          2            3                2            3    2   \n",
       "1      3     4          2            1                1            2    2   \n",
       "2      2     4          3            2                1            2    2   \n",
       "3      4     3          2            2                1            2    1   \n",
       "4      4     3          4            3                2            3    1   \n",
       "\n",
       "   avg_income  edu  \n",
       "0           3   11  \n",
       "1           2   12  \n",
       "2           2    4  \n",
       "3           2    3  \n",
       "4           1   12  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 将我们要用的数据转换成我想要的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 16)\n",
      "(7000,)\n",
      "(718, 16)\n",
      "(718,)\n",
      "(16, 7000)\n",
      "(16, 718)\n",
      "(5, 7000)\n",
      "(5, 718)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_X.shape)\n",
    "print(train_data_Y.shape)\n",
    "print(test_data_X.shape)\n",
    "print(test_data_Y.shape)\n",
    "train_data_X_ =train_data_X.T\n",
    "test_data_X_ = test_data_X.T\n",
    "\n",
    "#train_data_Y_ = train_data_Y.reshape((1, train_data_Y.shape[0]))\n",
    "#test_data_tY_ = test_data_Y.reshape((1, test_data_Y.shape[0]))\n",
    "test_data_Y_ = pd.get_dummies(test_data_Y).T\n",
    "train_data_Y_ = pd.get_dummies(train_data_Y).T #get_dummies one hot\n",
    "print(train_data_X_.shape)\n",
    "print(test_data_X_.shape)\n",
    "print(train_data_Y_.shape)\n",
    "print(test_data_Y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7250</th>\n",
       "      <th>7251</th>\n",
       "      <th>7252</th>\n",
       "      <th>7253</th>\n",
       "      <th>7255</th>\n",
       "      <th>7256</th>\n",
       "      <th>7257</th>\n",
       "      <th>7258</th>\n",
       "      <th>7260</th>\n",
       "      <th>7261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equity</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_status</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9     \\\n",
       "depression        5     3     5     4     3     4     2     5     2     4   \n",
       "class             3     6     5     5     1     8     2     2     3     5   \n",
       "health            3     5     4     4     5     5     2     3     2     4   \n",
       "equity            3     3     4     4     2     4     4     4     4     4   \n",
       "family_status     2     4     3     3     3     3     2     3     2     3   \n",
       "\n",
       "               ...   7250  7251  7252  7253  7255  7256  7257  7258  7260  \\\n",
       "depression     ...      5     2     4     3     4     4     3     4     5   \n",
       "class          ...      5     2     5     3     4     5     5     5     5   \n",
       "health         ...      4     2     4     3     5     3     2     4     2   \n",
       "equity         ...      4     4     4     3     2     4     2     4     4   \n",
       "family_status  ...      3     2     3     3     2     3     2     3     3   \n",
       "\n",
       "               7261  \n",
       "depression        4  \n",
       "class             2  \n",
       "health            4  \n",
       "equity            4  \n",
       "family_status     3  \n",
       "\n",
       "[5 rows x 7000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7250</th>\n",
       "      <th>7251</th>\n",
       "      <th>7252</th>\n",
       "      <th>7253</th>\n",
       "      <th>7255</th>\n",
       "      <th>7256</th>\n",
       "      <th>7257</th>\n",
       "      <th>7258</th>\n",
       "      <th>7260</th>\n",
       "      <th>7261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   7250  \\\n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "4     1     1     1     0     1     0     1     1     1     1  ...      1   \n",
       "5     0     0     0     1     0     1     0     0     0     0  ...      0   \n",
       "\n",
       "   7251  7252  7253  7255  7256  7257  7258  7260  7261  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     1     1     1     1     0     1     1     0     1  \n",
       "5     0     0     0     0     1     0     0     1     0  \n",
       "\n",
       "[5 rows x 7000 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_Y_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义所需函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    " \n",
    "    return A, cache\n",
    " \n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    " \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    " \n",
    "    assert (dZ.shape == Z.shape)\n",
    " \n",
    "    return dZ\n",
    " \n",
    "def relu(Z):\n",
    " \n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z \n",
    "    return A, cache\n",
    " \n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    " \n",
    "    assert (dZ.shape == Z.shape)\n",
    " \n",
    "    return dZ\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.初始化参数\n",
    "对于我们的demo，X(16,7000),n=16,m=7000,假设我们的这个方法包括输入层(16)，隐藏层(7)，和输入层(5)，\n",
    "则w1=(7,16)   w2=(4,7)   b1=(7,1)  b2=(5,1)  Z1=(7,7000)  Z2=(5,7000)\n",
    "\n",
    "    W[l]:(n[l],n[l-1])  \n",
    "    b[l]:(n[l],1)  \n",
    "    dW[l]:(n[l],n[l-1])  \n",
    "    db[l]:(n[l],1)  \n",
    "    Z[l]:(n[l],m)  \n",
    "    A[l]:(n[l],m)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "\n",
    "    np.random.seed(3)  #用于指定随机数生成时所用算法开始的整数值\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # 网络的层数\n",
    "\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 16 #输入参数的节点数,特征数\n",
    "n_h = 7 #隐藏层节点数\n",
    "n_y = 5 #结果类型\n",
    "layers_dims = (n_x,n_h,n_y)\n",
    "parameters =initialize_parameters_deep(layers_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.参数调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1前向传播\n",
    "    A[0]=X\n",
    "    Z[l]= W.A[l-1]+b\n",
    "    A[l]= g(Z[l])\n",
    "\n",
    " Z1=(6,7000);   Z2=(4,7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    linear_cache = (A_prev, W, b)\n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "\n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7000)\n"
     ]
    }
   ],
   "source": [
    "AL, caches=L_model_forward(train_data_X_,parameters)\n",
    "print(AL.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "  \n",
    "    cost = -np.sum(np.multiply(np.log(AL),Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m\n",
    "    ### END CODE HERE ###\n",
    "    cost = np.mean(cost)\n",
    "   # cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004949945921028664\n"
     ]
    }
   ],
   "source": [
    "cost=compute_cost(AL,train_data_Y_)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3反向传播\n",
    "    o对于第L层我们需要\n",
    "\n",
    "        dW[l] = 1/m*dZ[l]A[l-1].T    \n",
    "        db[l] = 1/m*ΣdZ[l][i]   \n",
    "        dA[l-1] = W[l].T*dZ[l]\n",
    "    o定义激活函数的梯度下降函数(relu_backward/sigmoid_backward) dZ= relu_backward(dA)\n",
    "    o综合以上两个步骤 [LINEAR->ACTIVATION] 反向传播方法得到 dW ,db,dA\n",
    "    o循环执行[LINEAR->RELU] L-1  次( 1 到L-1层) 在最后一层执行 [LINEAR->SIGMOID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        ### END CODE HERE ###\n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    B = np.array(dZ)\n",
    "    db = np.sum(B, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "  #  Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL(4,7000)\n",
    "\n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "\n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads =L_model_backward(AL, train_data_Y_, caches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 修改参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(parameters,X,Y,num_iterations,learning_rate,print_cost):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        #FORWARD PROPAGATION\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after interation %i:%f\"%(i,cost))\n",
    "\n",
    "        # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        # update rule\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    return parameters,costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_layer_model(X,Y,layers_dims,learning_rate=0.0075,num_iterations=3000,print_cost=False,isPlot=True):\n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []\n",
    "    (n_x,n_h,n_y) = layers_dims\n",
    "\n",
    "    \"\"\"\n",
    "    初始化参数\n",
    "    \"\"\"\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    \"\"\"\n",
    "    开始进行迭代\n",
    "    \"\"\"\n",
    "    parameters,costs= optimize(parameters,X,Y,num_iterations,learning_rate,print_cost)\n",
    "        \n",
    "        \n",
    "    #迭代完成，根据条件绘制图\n",
    "    if isPlot:\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "    #返回parameters\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.测试\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after interation 0:0.000495\n",
      "Cost after interation 100:0.000265\n",
      "Cost after interation 200:0.000260\n",
      "Cost after interation 300:0.000260\n",
      "Cost after interation 400:0.000259\n",
      "Cost after interation 500:0.000259\n",
      "Cost after interation 600:0.000259\n",
      "Cost after interation 700:0.000259\n",
      "Cost after interation 800:0.000259\n",
      "Cost after interation 900:0.000259\n",
      "Cost after interation 1000:0.000258\n",
      "Cost after interation 1100:0.000258\n",
      "Cost after interation 1200:0.000258\n",
      "Cost after interation 1300:0.000258\n",
      "Cost after interation 1400:0.000258\n",
      "Cost after interation 1500:0.000257\n",
      "Cost after interation 1600:0.000257\n",
      "Cost after interation 1700:0.000257\n",
      "Cost after interation 1800:0.000257\n",
      "Cost after interation 1900:0.000257\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141a1434eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_x = 16 #输入参数的节点数,特征数\n",
    "n_h = 6 #隐藏层节点数\n",
    "n_y = 5 #结果类型\n",
    "layers_dims = (n_x,n_h,n_y)\n",
    "\n",
    "parameters = n_layer_model(train_data_X_, train_data_Y_, layers_dims = (n_x, n_h, n_y), num_iterations = 2000, print_cost=True,isPlot=True)\n",
    "\n",
    "\n",
    "#test_data_X test_data_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 718)\n"
     ]
    }
   ],
   "source": [
    "AL, caches=L_model_forward(test_data_X_,parameters)\n",
    "print(AL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00695801 0.00473196 0.03271093 ... 0.01009948 0.00248321 0.00220108]\n",
      " [0.04441982 0.03509995 0.11095236 ... 0.05539446 0.02372147 0.02201056]\n",
      " [0.12655726 0.11030728 0.21187051 ... 0.14300255 0.08815252 0.08424791]\n",
      " [0.62220562 0.63378721 0.57303274 ... 0.61108973 0.65306618 0.65601521]\n",
      " [0.18975055 0.17668416 0.24691472 ... 0.2027178  0.15663823 0.1530186 ]]\n"
     ]
    }
   ],
   "source": [
    "print(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7000)\n",
      "[[0.00874026 0.00234538 0.00402419 ... 0.00752929 0.00479426 0.00885176]\n",
      " [0.05126141 0.02283747 0.03172248 ... 0.04631876 0.03536041 0.05147652]\n",
      " [0.13829087 0.08598358 0.10373379 ... 0.12874331 0.11072516 0.13804359]\n",
      " [0.61322578 0.65605301 0.63922083 ... 0.62068073 0.63396013 0.61310698]\n",
      " [0.19383891 0.15593132 0.1724951  ... 0.1938238  0.17787152 0.19482389]]\n"
     ]
    }
   ],
   "source": [
    "AL2, caches=L_model_forward(train_data_X_,parameters)\n",
    "print(AL2.shape)\n",
    "print(AL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_class = np.argmax(AL, axis=0)\n",
    "\n",
    "result = np.zeros((AL.shape[1],), dtype = int)\n",
    "for i in range(AL.shape[1]):\n",
    "    maxindex =0\n",
    "    maxvalue =0\n",
    "    for j in range(AL.shape[0]):\n",
    "        if AL[j, i] >= maxvalue:\n",
    "            maxindex = j\n",
    "            maxvalue = AL[j, i]\n",
    "                 \n",
    "    \n",
    "    result[i]=maxindex+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape ==test_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.60\n",
      "test accuracy: 51.1142061281337 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.2f\" % (np.mean(result == test_data_Y)))\n",
    "#print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(result - test_data_Y)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#方差\n",
    "np.var(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对矩阵求标准差\n",
    "np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "  \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "  \n",
    "        ### END CODE HERE ###\n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
