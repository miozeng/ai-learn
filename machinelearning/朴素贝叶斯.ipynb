{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/apachecn/AiLearning/blob/dev/blog/ml/4.%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯理论\n",
    "贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。本章首先介绍贝叶斯分类算法的基础——贝叶斯定理。最后，我们通过实例来讨论贝叶斯分类的中最简单的一种: 朴素贝叶斯分类。\n",
    "\n",
    "我们现在用 p1(x,y) 表示数据点 (x,y) 属于类别 的概率，用 p2(x,y) 表示数据点 (x,y) 属于类别 2的概率，那么对于一个新数据点 (x,y)，可以用下面的规则来判断它的类别：\n",
    "如果 p1(x,y) > p2(x,y) ，那么类别为1\n",
    "如果 p2(x,y) > p1(x,y) ，那么类别为2\n",
    "也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用条件概率来分类\n",
    "这并不是贝叶斯决策理论的所有内容。使用 p1() 和 p2() 只是为了尽可能简化描述，而真正需要计算和比较的是 p(c1|x, y) 和 p(c2|x, y) .这些符号所代表的具体意义是: 给定某个由 x、y 表示的数据点，那么该数据点来自类别 c1 的概率是多少？数据点来自类别 c2 的概率又是多少？注意这些概率与概率 p(x, y|c1) 并不一样，不过可以使用贝叶斯准则来交换概率中条件与结果。具体地，应用贝叶斯准则得到:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lena = plt.imread('img/NB_5.png')\n",
    "plt.imshow(lena)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用上面这些定义，可以定义贝叶斯分类准则为:\n",
    "\n",
    "如果 P(c1|x, y) > P(c2|x, y), 那么属于类别 c1;\n",
    "如果 P(c2|x, y) > P(c1|x, y), 那么属于类别 c2.\n",
    "在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。\n",
    "\n",
    "我们假设特征之间 相互独立 。所谓 独立(independence) 指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系，比如说，“我们”中的“我”和“们”出现的概率与这两个字相邻没有任何关系。这个假设正是朴素贝叶斯分类器中 朴素(naive) 一词的含义。朴素贝叶斯分类器中的另一个假设是，每个特征同等重要。\n",
    "\n",
    "Note: 朴素贝叶斯分类器通常有两种实现方式: 一种基于伯努利模型实现，一种基于多项式模型实现。这里采用前一种实现方式。该实现方式中并不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是等权重的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯 场景\n",
    "机器学习的一个重要应用就是文档的自动分类。\n",
    "\n",
    "在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。\n",
    "\n",
    "朴素贝叶斯是上面介绍的贝叶斯分类器的一个扩展，是用于文档分类的常用算法。下面我们会进行一些朴素贝叶斯分类的实践项目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 项目案例: 屏蔽社区留言板的侮辱性言论\n",
    "构建一个快速过滤器来屏蔽在线社区留言板上的侮辱性言论。如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标识为内容不当。对此问题建立两个类别: 侮辱类和非侮辱类，使用 1 和 0 分别表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1. 加载数据集\n",
    " 单词列表postingList, 所属类别classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], #[0,0,1,1,1......]\n",
    "                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "classVec = [0, 1, 0, 1, 0, 1]  # 1 is abusive, 0 not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 创建单词集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has', 'I', 'cute', 'stop', 'flea', 'mr', 'ate', 'food', 'take', 'stupid', 'dog', 'him', 'worthless', 'quit', 'steak', 'dalmation', 'love', 'garbage', 'how', 'my', 'licks', 'please', 'to', 'is', 'help', 'so', 'posting', 'problems', 'maybe', 'buying', 'not', 'park']\n"
     ]
    }
   ],
   "source": [
    "    vocabSet = set([])  # create empty set\n",
    "    for document in postingList:\n",
    "        # 操作符 | 用于求两个集合的并集\n",
    "        vocabSet = vocabSet | set(document)  # union of the two sets\n",
    "    myVocabList = list(vocabSet)\n",
    "    print(myVocabList)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3. 计算单词是否出现并创建数据矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    \"\"\"\n",
    "    遍历查看该单词是否出现，出现该单词则将该单词置1\n",
    "    :param vocabList: 所有单词集合列表\n",
    "    :param inputSet: 输入数据集\n",
    "    :return: 匹配列表[0,1,0,1...]，其中 1与0 表示词汇表中的单词是否出现在输入的数据集中\n",
    "    \"\"\"\n",
    "    # 创建一个和词汇表等长的向量，并将其元素都设置为0\n",
    "    returnVec = [0] * len(vocabList)# [0,0......]\n",
    "    # 遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print (\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "trainMat = []\n",
    "for postinDoc in postingList:\n",
    "    # 返回m*len(myVocabList)的矩阵， 记录的都是0，1信息\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
    "print(trainMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4. 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[-3.04452244 -3.04452244 -3.04452244 -2.35137526 -3.04452244 -3.04452244\n",
      " -3.04452244 -2.35137526 -2.35137526 -1.65822808 -1.94591015 -2.35137526\n",
      " -1.94591015 -2.35137526 -3.04452244 -3.04452244 -3.04452244 -2.35137526\n",
      " -3.04452244 -3.04452244 -3.04452244 -3.04452244 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244 -2.35137526 -3.04452244 -2.35137526 -2.35137526\n",
      " -2.35137526 -2.35137526]\n",
      "[-2.56494936 -2.56494936 -2.56494936 -2.56494936 -2.56494936 -2.56494936\n",
      " -2.56494936 -3.25809654 -3.25809654 -3.25809654 -2.56494936 -2.15948425\n",
      " -3.25809654 -3.25809654 -2.56494936 -2.56494936 -2.56494936 -3.25809654\n",
      " -2.56494936 -1.87180218 -2.56494936 -2.56494936 -2.56494936 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -3.25809654\n",
      " -3.25809654 -3.25809654]\n"
     ]
    }
   ],
   "source": [
    "    trainMatrix =  array(trainMat)#文件单词矩阵\n",
    "    trainCategory = array(classVec) #文件对应的类别\n",
    "    # 总文件数\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    # 总单词数\n",
    "    numWords = len(trainMatrix[0])\n",
    "    # 侮辱性文件的出现概率\n",
    "    pAbusive = sum(trainCategory) / float(numTrainDocs) #因为侮辱性的词是1，非侮辱性是0，所以sum(trainCategory)是侮辱性的总和\n",
    "    # 构造单词出现次数列表\n",
    "    # p0Num 正常的统计\n",
    "    # p1Num 侮辱的统计\n",
    "    p0Num = ones(numWords)#[0,0......]->[1,1,1,1,1.....]\n",
    "    p1Num = ones(numWords) #\n",
    "\n",
    "    # 整个数据集单词出现总数，2.0根据样本/实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）\n",
    "    # p0Denom 正常的统计\n",
    "    # p1Denom 侮辱的统计\n",
    "    p0Denom = 2.0\n",
    "    p1Denom = 2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            # 累加辱骂词的频次\n",
    "            p1Num += trainMatrix[i]\n",
    "            # 对每篇文章的辱骂的频次 进行统计汇总\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    # 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表\n",
    "    p1Vect = log(p1Num / p1Denom)\n",
    "    # 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表\n",
    "    p0Vect = log(p0Num / p0Denom)\n",
    "    \n",
    "    print(pAbusive);\n",
    "    print(p1Vect);\n",
    "    print(p0Vect);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 测试数据\n",
    "计算公式  log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "p0\n"
     ]
    }
   ],
   "source": [
    "# 我的理解是：这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来\n",
    "testEntry = ['love', 'my', 'dalmation']\n",
    "vec2Classify = array(setOfWords2Vec(myVocabList, testEntry))   \n",
    "print(vec2Classify)\n",
    "p1 = sum(vec2Classify * p1Vect) + log(pAbusive) # P(w|c1) * P(c1) ，即贝叶斯准则的分子\n",
    "p0 = sum(vec2Classify * p0Vect) + log(1.0 - pAbusive) # P(w|c0) * P(c0) ，即贝叶斯准则的分子·\n",
    "if p1 > p0:\n",
    "    print(\"p1\")\n",
    "else:\n",
    "    print(\"p0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
