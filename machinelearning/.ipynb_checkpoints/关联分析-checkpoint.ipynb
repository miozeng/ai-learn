{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori算法\n",
    "Apriori算法使用一种称为逐层搜索的迭代方法，其中k项集用于探索(k+1)项集。首先，通过扫描数据库，累计每个项的计数，并收集满足最小支持度的项，找出频繁1项集的集合。该集合记为L1。然后，使用L1找出频繁2项集的集合L2，使用L2找出L3，如此下去，直到不能再找到频繁k项集。每找出一个Lk需要一次数据库的完整扫描。Apriori算法使用频繁项集的先验性质来压缩搜索空间。\n",
    "\n",
    "\n",
    "交易码   商品\n",
    "0       豆奶，莴苣\n",
    "1       莴苣，尿布，葡萄酒，甜菜\n",
    "2       豆奶，尿布，葡萄酒，橙汁\n",
    "3       莴苣，豆奶，尿布，葡萄酒\n",
    "4       莴苣，豆奶，尿布，橙汁\n",
    "\n",
    "\n",
    "#### 1.基本概念\n",
    "\n",
    "项与项集：设itemset={item1, item_2, …, item_m}是所有项的集合，其中，item_k(k=1,2,…,m)成为项。项的集合称为项集（itemset），包含k个项的项集称为k项集(k-itemset)。\n",
    "\n",
    "事务与事务集：一个事务T是一个项集，它是itemset的一个子集，每个事务均与一个唯一标识符Tid相联系。不同的事务一起组成了事务集D，它构成了关联规则发现的事务数据库。\n",
    "\n",
    "关联规则: 尿布 -> 葡萄酒 就是一个关联规则。这意味着如果顾客买了尿布，那么他很可能会买葡萄酒。\n",
    "\n",
    "\n",
    "支持度: 数据集中包含该项集的记录所占的比例。关联规则A->B的支持度support=P(AB)，指的是事件A和事件B同时发生的概率。例如上图中，{豆奶} 的支持度为 4/5。{豆奶, 尿布} 的支持度为 3/5。\n",
    "\n",
    "可信度: confidence=P(B|A)=P(AB)/P(A) 指的是发生事件A的基础上发生事件B的概率。针对一条诸如 {尿布} -> {葡萄酒} 这样具体的关联规则来定义的。这条规则的 可信度 被定义为 支持度({尿布, 葡萄酒})/支持度({尿布})，从图中可以看出 支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -> {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。\n",
    "\n",
    "\n",
    "\n",
    "#### 2.实现步骤\n",
    "一般而言，关联规则的挖掘是一个两步的过程：\n",
    "找出所有的频繁项集\n",
    "由频繁项集产生强关联规则\n",
    "\n",
    "\n",
    "#### 3.Apriori 算法优缺点\n",
    "\n",
    "    * 优点：易编码实现\n",
    "    * 缺点：在大数据集上可能较慢\n",
    "    * 适用数据类型：数值型 或者 标称型数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-growth 算法简介\n",
    "一种非常好的发现频繁项集算法。基于Apriori算法构建,但是数据结构不同，使用叫做 FP树 的数据结构结构来存储集合。下面我们会介绍这种数据结构。\n",
    "\n",
    "\n",
    "#### 1.FP树的节点结构如下:\n",
    "\n",
    "    class treeNode:\n",
    "        def __init__(self, nameValue, numOccur, parentNode):\n",
    "            self.name = nameValue     # 节点名称\n",
    "            self.count = numOccur     # 节点出现次数\n",
    "            self.nodeLink = None      # 不同项集的相同项通过nodeLink连接在一起\n",
    "            # needs to be updated\n",
    "            self.parent = parentNode  # 指向父节点\n",
    "            self.children = {}        # 存储叶子节点\n",
    "\n",
    "#### 2.原理\n",
    "以下文章低FP做了比较清晰的解释，如果要理解LP推荐此文章\n",
    "https://www.cnblogs.com/pinard/p/6307064.html\n",
    "\n",
    "#### 3.FP-growth 算法优缺点:\n",
    "\n",
    "    * 优点： 1. 因为 FP-growth 算法只需要对数据集遍历两次，所以速度更快。\n",
    "            2. FP树将集合按照支持度降序排序，不同路径如果有相同前缀路径共用存储空间，使得数据得到了压缩。\n",
    "            3. 不需要生成候选集。\n",
    "            4. 比Apriori更快。\n",
    "    * 缺点： 1. FP-Tree第二次遍历会存储很多中间过程的值，会占用很多内存。\n",
    "            2. 构建FP-Tree是比较昂贵的。\n",
    "    * 适用数据类型：标称型数据(离散型数据)。\n",
    "\n",
    "\n",
    "#### 4.FP的实现\n",
    "https://www.jianshu.com/p/bf93c1bd02bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例说明\n",
    " 假设有一个数据库D，其中有4个事务记录，分别表示为：\n",
    " \n",
    "    交易码   商品\n",
    "    0       l1, l3, l4\n",
    "    1       l2, l3, l5\n",
    "    2       l1, l2, l3, l5\n",
    "    3       l2, l5\n",
    "\n",
    "预定最小支持度minSupport=2\n",
    "\n",
    "1、扫描D，对每个候选项进行支持度计数得到表C1:\n",
    "\n",
    "    项集  支持度计数\n",
    "    l1      2\n",
    "    l2      3\n",
    "    l3      3\n",
    "    l4      1\n",
    "    l5      3\n",
    "\n",
    "\n",
    "2、比较候选项支持度计数与最小支持度minSupport，产生1维最大项目集L1\n",
    "\n",
    "    项集  支持度计数\n",
    "    l1      2\n",
    "    l2      3\n",
    "    l3      3\n",
    "    l5      3\n",
    "\n",
    "3、由L1产生候选项集C2：\n",
    "\n",
    "    项集  \n",
    "    l1,l2      \n",
    "    l1,l3      \n",
    "    l1,l4      \n",
    "    l2 ,l3     \n",
    "    l2 ,l5     \n",
    "    l3,l5   \n",
    "\n",
    "4、扫描D，对每个候选项集进行支持度计数:\n",
    "\n",
    "    项集  支持度计数\n",
    "    l1,l2      1\n",
    "    l1,l3      2\n",
    "    l1,l4      1\n",
    "    l2 ,l3     2\n",
    "    l2 ,l5     3\n",
    "    l3,l5      2\n",
    "\n",
    "5、比较候选项支持度计数与最小支持度minSupport，产生2维最大项目集L2：\n",
    "\n",
    "    项集  支持度计数\n",
    "    l1,l3      2\n",
    "    l2 ,l3     2\n",
    "    l2 ,l5     3\n",
    "    l3,l5      2\n",
    "\n",
    "6、由L2产生候选项集C3：\n",
    "\n",
    "    l2,l3,l5\n",
    "\n",
    "7、比较候选项支持度计数与最小支持度minSupport，产生3维最大项目集L3：\n",
    "\n",
    "    项集  支持度计数\n",
    "    l2,l3,l5      2\n",
    "\n",
    "8、算法终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1、扫描D，对每个候选项进行支持度计数得到表C1:\n",
    " 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    \"\"\"createC1（创建集合 C1）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "    Returns:\n",
    "        frozenset 返回一个 frozenset 格式的 list\n",
    "    \"\"\"\n",
    "\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                # 遍历所有的元素，如果不在 C1 出现过，那么就 append\n",
    "                C1.append([item])\n",
    "    # 对数组进行 `从小到大` 的排序\n",
    "    print( 'sort 前=', C1)\n",
    "    C1.sort()\n",
    "    # frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用\n",
    "    print('sort 后=', C1) \n",
    "    print('frozenset=', map(frozenset, C1)) \n",
    "    return map(frozenset, C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "dataSet =  loadDataSet()\n",
    "# C1 = createC1(dataSet)\n",
    "D = map(set, dataSet)\n",
    "numItems = float(len(list(D)))\n",
    "print(numItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanD(D, Ck, minSupport):\n",
    "    \"\"\"scanD（计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度 minSupport 的数据）\n",
    "\n",
    "    Args:\n",
    "        D 数据集\n",
    "        Ck 候选项集列表\n",
    "        minSupport 最小支持度\n",
    "    Returns:\n",
    "        retList 支持度大于 minSupport 的集合\n",
    "        supportData 候选项集支持度数据\n",
    "    \"\"\"\n",
    "\n",
    "    # ssCnt 临时存放选数据集 Ck 的频率. 例如: a->10, b->5, c->8\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            # s.issubset(t)  测试是否 s 中的每一个元素都在 t 中\n",
    "            if can.issubset(tid):\n",
    "                if not  can in ssCnt: \n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "#     D=list(map(set,dataSet))\n",
    "#     numItems = float(len(D))\n",
    "    print(list(D))\n",
    "    numItems = float(len(list(D))) # 数据集 D 的数量\n",
    "    print('numItems',numItems)\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        # 支持度 = 候选项（key）出现的次数 / 所有数据集的数量\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support >= minSupport:\n",
    "            # 在 retList 的首位插入元素，只存储支持度满足频繁项集的值\n",
    "            retList.insert(0, key)\n",
    "        # 存储所有的候选项（key）和对应的支持度（support）\n",
    "        supportData[key] = support\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "numItems 4.0\n",
      "[]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "retList, supportData = scanD(dataSet, C1, 2)\n",
    "print(retList)\n",
    "print(supportData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "def aprioriGen(Lk, k):\n",
    "    \"\"\"aprioriGen（输入频繁项集列表 Lk 与返回的元素个数 k，然后输出候选项集 Ck。\n",
    "       例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "       仅需要计算一次，不需要将所有的结果计算出来，然后进行去重操作\n",
    "       这是一个更高效的算法）\n",
    "\n",
    "    Args:\n",
    "        Lk 频繁项集列表\n",
    "        k 返回的项集元素个数（若元素的前 k-2 相同，就进行合并）\n",
    "    Returns:\n",
    "        retList 元素两两合并的数据集\n",
    "    \"\"\"\n",
    "    \n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[: k-2]\n",
    "            L2 = list(Lk[j])[: k-2]\n",
    "            # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]\n",
    "            # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            # 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集\n",
    "            # if first k-2 elements are equal\n",
    "            if L1 == L2:\n",
    "                # set union\n",
    "                # print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"apriori（首先构建集合 C1，然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度的要求。那么满足最小支持度要求的项集构成集合 L1。然后 L1 中的元素相互组合成 C2，C2 再进一步过滤变成 L2，然后以此类推，知道 CN 的长度为 0 时结束，即可找出所有频繁项集的支持度。）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "        minSupport 支持度的阈值\n",
    "    Returns:\n",
    "        L 频繁项集的全集\n",
    "        supportData 所有元素和支持度的全集\n",
    "    \"\"\"\n",
    "    # C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset\n",
    "    C1 = createC1(dataSet)\n",
    "    # 对每一行进行 set 转换，然后存放到集合中\n",
    "    D = map(set, dataSet)\n",
    "    print('D=', D) \n",
    "    # 计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "    L1, supportData = scanD(dataSet, C1, minSupport)\n",
    "    # print \"L1=\", L1, \"\\n\", \"outcome: \", supportData\n",
    "\n",
    "    # L 加了一层 list, L 一共 2 层 list\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    # 判断 L 的第 k-2 项的数据长度是否 > 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1\n",
    "    while (len(L[k-2]) > 0):\n",
    "        print('k=', k, L, L[k-2])\n",
    "        Ck = aprioriGen(L[k-2], k) # 例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "        print('Ck', Ck) \n",
    "\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "        # 保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素\n",
    "        supportData.update(supK)\n",
    "        if len(Lk) == 0:\n",
    "            break\n",
    "        # Lk 表示满足频繁子项的集合，L 元素在增加，例如: \n",
    "        # l=[[set(1), set(2), set(3)]]\n",
    "        # l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "        # print 'k=', k, len(L[k-2])\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataSet:  [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "sort 前= [[1], [3], [4], [2], [5]]\n",
      "sort 后= [[1], [2], [3], [4], [5]]\n",
      "frozenset= <map object at 0x000001BD6FF9EF28>\n",
      "D= <map object at 0x000001BD6FF9EAC8>\n",
      "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "numItems 4.0\n",
      "L(0.7):  [[]]\n",
      "supportData(0.7):  {frozenset({1}): 0.25, frozenset({3}): 0.25, frozenset({4}): 0.25}\n",
      "->->->->->->->->->->->->->->->->->->->->->->->->->->->->\n",
      "sort 前= [[1], [3], [4], [2], [5]]\n",
      "sort 后= [[1], [2], [3], [4], [5]]\n",
      "frozenset= <map object at 0x000001BD70098128>\n",
      "D= <map object at 0x000001BD70098160>\n",
      "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "numItems 4.0\n",
      "L(0.5):  [[]]\n",
      "supportData(0.5):  {frozenset({1}): 0.25, frozenset({3}): 0.25, frozenset({4}): 0.25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载测试数据集\n",
    "dataSet = loadDataSet()\n",
    "print('dataSet: ', dataSet)\n",
    "\n",
    "# Apriori 算法生成频繁项集以及它们的支持度\n",
    "L1, supportData1 = apriori(dataSet, minSupport=0.7)\n",
    "print('L(0.7): ', L1)\n",
    "print('supportData(0.7): ', supportData1)\n",
    "\n",
    "print('->->->->->->->->->->->->->->->->->->->->->->->->->->->->')\n",
    "\n",
    "# Apriori 算法生成频繁项集以及它们的支持度\n",
    "L2, supportData2 = apriori(dataSet, minSupport=0.5)\n",
    "print('L(0.5): ', L2)\n",
    "print('supportData(0.5): ', supportData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算可信度（confidence）\n",
    "def calcConf(freqSet, H\n",
    ", supportData, brl, minConf=0.7):\n",
    "    \"\"\"calcConf（对两个元素的频繁项，计算可信度，例如： {1,2}/{1} 或者 {1,2}/{2} 看是否满足条件）\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的空数组\n",
    "        minConf 最小可信度\n",
    "    Returns:\n",
    "        prunedH 记录 可信度大于阈值的集合\n",
    "    \"\"\"\n",
    "    # 记录可信度大于最小可信度（minConf）的集合\n",
    "    prunedH = []\n",
    "    for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度\n",
    "\n",
    "        # print 'confData=', freqSet, H, conseq, freqSet-conseq\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]\n",
    "        if conf >= minConf:\n",
    "            # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq 集合是全集）\n",
    "            print( freqSet-conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归计算频繁项集的规则\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"rulesFromConseq\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的数组\n",
    "        minConf 最小可信度\n",
    "    \"\"\"\n",
    "    # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制\n",
    "    # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...\n",
    "    # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "    # 那么 m = len(H[0]) 的递归的值依次为 1 2\n",
    "    # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        print('freqSet******************', len(freqSet), m + 1, freqSet, H, H[0]) \n",
    "        # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]\n",
    "        # 第二次 。。。没有第二次，递归条件判断时已经退出了\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        # 返回可信度大于最小可信度的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        print ('Hmp1=', Hmp1)\n",
    "        print ('len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet))\n",
    "        # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归\n",
    "        if (len(Hmp1) > 1):\n",
    "            print( '----------------------', Hmp1)\n",
    "            # print len(freqSet),  len(Hmp1[0]) + 1\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"generateRules\n",
    "\n",
    "    Args:\n",
    "        L 频繁项集列表\n",
    "        supportData 频繁项集支持度的字典\n",
    "        minConf 最小置信度\n",
    "    Returns:\n",
    "        bigRuleList 可信度规则列表（关于 (A->B+置信度) 3个字段的组合）\n",
    "    \"\"\"\n",
    "    bigRuleList = []\n",
    "    # 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]\n",
    "    for i in range(1, len(L)):\n",
    "        # 获取频繁项集中每个组合的所有元素\n",
    "        for freqSet in L[i]:\n",
    "            # 假设：freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]\n",
    "            # 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 2 个的组合，走 else, 2 个以上的组合，走 if\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataSet:  [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "sort 前= [[1], [3], [4], [2], [5]]\n",
      "sort 后= [[1], [2], [3], [4], [5]]\n",
      "frozenset= <map object at 0x000001BD6E5964E0>\n",
      "D= <map object at 0x000001BD6FF9EA58>\n",
      "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "numItems 4.0\n",
      "L(0.7):  [[]]\n",
      "supportData(0.7):  {frozenset({1}): 0.25, frozenset({3}): 0.25, frozenset({4}): 0.25}\n",
      "rules:  []\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据集\n",
    "dataSet = loadDataSet()\n",
    "print('dataSet: ', dataSet)\n",
    "\n",
    "# Apriori 算法生成频繁项集以及它们的支持度\n",
    "L1, supportData1 = apriori(dataSet, minSupport=0.5)\n",
    "print('L(0.7): ', L1)\n",
    "print('supportData(0.7): ', supportData1)\n",
    "\n",
    "# 生成关联规则\n",
    "rules = generateRules(L1, supportData1, minConf=0.5)\n",
    "print('rules: ', rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(url,headers):\n",
    "    r = requests.get(url,headers=headers,verify=False)\n",
    "    testlist = json.loads(r.text)\n",
    "    for filelist in testlist[files]:\n",
    "        if filelist['ftype'] == 'folders':\n",
    "            flodeurl='';\n",
    "            readFile(flodeurl,headers)\n",
    "        fileurl='';\n",
    "        print(fileurl)\n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
