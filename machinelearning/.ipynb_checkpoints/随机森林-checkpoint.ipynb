{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### 集成学习\n",
    "集成学习是将多个模型进行组合来解决单一的预测问题。它的原理是生成多个分类器模型，各自独立地学习并作出预测。这些预测最后结合起来得到预测结果，因此和单独分类器的结果相比，结果一样或更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林\n",
    "是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。\n",
    "\n",
    "随机森林特点：\n",
    "数据的随机性化；待选特征的随机化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林的构造过程\n",
    "\n",
    "　　1. 假如有N个样本，则有放回的随机选择N个样本(每次随机选择一个样本，然后返回继续选择)。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。\n",
    "\n",
    "　　2. 所有特征中随机选择k个特征，对选出的样本利用这些特征建立决策树（一般是CART，也可是别的或混合）； \n",
    "\n",
    "　　3. 重复以上两步m次，即生成m棵决策树，形成随机森林； \n",
    "  \n",
    "   4. 然后统计子决策树的投票结果，得到最终的分类 就是 随机森林的输出结果。\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林优缺点\n",
    "    随机森林有很多优点： \n",
    "    1） 每棵树都选择部分样本及部分特征，一定程度避免过拟合； \n",
    "    2） 每棵树随机选择样本并随机选择特征，使得具有很好的抗噪能力，性能稳定； \n",
    "    3） 能处理很高维度的数据，并且不用做特征选择； \n",
    "    4） 适合并行计算； \n",
    "    5） 实现比较简单； \n",
    "    缺点： \n",
    "    1） 参数较复杂； \n",
    "    2） 模型训练和预测都比较慢。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林主要用途\n",
    "1.特征选择\n",
    "  你可以检查变量在每棵树中表现的是最佳还是最糟糕。当一些树使用一个变量，而其他的不使用这个变量，你就可以对比信息的丢失或增加。\n",
    "2.分类\n",
    "  它可以被用于为多个可能目标类别做预测，它也可以在调整后输出概率。\n",
    "3.回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用： \n",
    "随机森林算法在大部分数据处理软件中都有实现，使用时可以直接调用，只需指定所需参数。 \n",
    "随机森林模型训练前要设置的参数较多，按PAI平台的实现有如下几个： \n",
    "o 算法类型：（可选）可供选择的算法类型有id3算法、cart算法、c4.5算法以及默认情况下的将上述三种算法均分的混合算法 \n",
    "o 树的数目：森林中树的个数, 范围(0, 1000] \n",
    "o 随机属性个数：（可选）单颗树在生成时，每次选择最优特征，随机的特征个数。可供选择的类型有logN，N/3，sqrtN，N四种类型，其中N为属性总数 \n",
    "o 树最大深度：（可选）单颗树的最大深度，范围[1, ∞)，-1表示完全生长。 \n",
    "o 叶子节点最少记录数：（可选）叶节点数据的最小个数。最小个数为2 \n",
    "o 叶子节点最少记录百分比：（可选）叶节点数据个数占父节点的最小比例，范围[0,100]，-1表示无限制。默认-1 \n",
    "o 每棵树最大记录数：（可选）森林中单颗树输入的随机数据的个数。范围为(1000, 1000000] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-8359ea0c93ee>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-8359ea0c93ee>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    clf = RandomForestClassifier(n_jobs=2)y, _ = pd.factorize(train['species'])\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df.head()\n",
    "\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "features = df.columns[:4]\n",
    "clf = RandomForestClassifier(n_jobs=2)y, _ = pd.factorize(train['species'])\n",
    "clf.fit(train[features], y)\n",
    "\n",
    "preds = iris.target_names[clf.predict(test[features])]\n",
    "\n",
    "pd.crosstab(test['species'], preds, rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
