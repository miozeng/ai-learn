{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像特征提取\n",
    "- 应用：图像拼接、图像匹配\n",
    "- 特征检测和提取算法：Harris（检测角点）SIFT（检测斑点blob）SURF（检测斑点）FAST（检测角点）BRIEF（检测斑点）ORB（带方向的FAST算法与具有旋转不变性的BRIEF算法）\n",
    "- 特征匹配算法：暴力匹配（Brute-Force）基于FLANN匹配。\n",
    "- 特征：特殊的图形区域、独特性和易于识别性--角点和高密度区域。大量重复区域和低密度区域不适合作为特征，边缘时很好的特征，斑点（与周围有很大差别的区域）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各类算法对比\n",
    "#### FAST\n",
    "\n",
    "    原理简单\n",
    "    执行速度相当快\n",
    "    主要用于侦测corners，亦可侦测blob。\n",
    "    适用于要求速度的real-time analysis\n",
    "    适用于速度慢或较低阶的执行环境。\n",
    "    使用度极高，尤其在需要即时的realtime环境。\n",
    "\n",
    "    fast = cv2.FastFeatureDetector()\n",
    "\n",
    "    \n",
    "#### Harris\n",
    "\n",
    "    速度相当快，但仍较FAST慢，不过侦测corner比起FAST准确一些。\n",
    "    广泛应用于侦测edges及corners\n",
    "\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "    \n",
    "##### cv2.cornerHarris() \n",
    "    - img： 数据类型为 ﬂoat32 的入图像\n",
    "    - blockSize： 角点检测中指定区域的大小\n",
    "    - ksize： Sobel求导中使用的窗口大小 \n",
    "    - k： 取值参数为 [0,04,0.06]\n",
    "    \n",
    "#### GFTT\n",
    "\n",
    "    GFTT为Harris keypoint detector的再修正。\n",
    "    针对edges/corner detect的准确率与速度有所提升，但实际上使用感觉差异不大。\n",
    "\n",
    "    detector = cv2.FeatureDetector_create(“GFTT\")\n",
    "    kps = detector.detect(gray)\n",
    "\n",
    "#### DoG (SIFT)\n",
    "\n",
    "    原理较为复杂。\n",
    "    主要针对blob 侦测，不过亦可侦测corners。\n",
    "    可适应物件的scale(大小变化)及angle（旋转角度）等情况。\n",
    "    在DoG模型中，使用了不同尺寸影像并套用高斯模糊，比较不同模糊比例之间的变化，来决定是否为keypoint。\n",
    "    由于计算量大，DoG的执行速度较慢，不适用于realtime的环境。\n",
    "    SIFT已广泛的应用于电脑视觉领域，并成为评定新keypoint detecter的效率指标。\n",
    "\n",
    "    sift = cv2.SIFT()\n",
    "\n",
    "#### Fast Hessian (SURF)\n",
    "\n",
    "    基于DoG（SIFT）模型而发展，改善其速度慢的缺点。\n",
    "    可使用于realtime的环境，但速度仍比不上FAST等keypoint detector。\n",
    "    与DoG相同，用于侦测corners以及明显材质纹路的textures。\n",
    "    \n",
    "    \n",
    "#### STAR\n",
    "\n",
    "    使用于侦测blog area。\n",
    "    与DoG相同，亦使用高斯模糊计算，但由于其演算方式相当复杂，目前并不常被使用。\n",
    "    侦测速度相当快，可应用于realtime分析，但效果并不如FAST。\n",
    "    \n",
    "#### MSER\n",
    "\n",
    "    1. 使用于侦测blog area\n",
    "\n",
    "    2. 判断的依据（需满足此三点），则认定为blog area：\n",
    "\n",
    "        a. 相连的像素\n",
    "\n",
    "        b. 相似的像素强度\n",
    "\n",
    "        c. 与背景成对比\n",
    "\n",
    "    3. 对于小区域且对比明显的area侦测效果良好。\n",
    "\n",
    "    4. 不适用分析模糊的影像。\n",
    "\n",
    "    5. 不适合使用于要求速度的realtime环境。\n",
    "\n",
    "    6. 输入的影像符合其要求的三种条件，则侦测速度可加快。\n",
    "\n",
    "#### Dense\n",
    "\n",
    "    Dense是最简单的keypoint detector。\n",
    "    它的原理是先设定一个K值，然后均匀的在整张图面上以每隔K pixels的距离布置一个keypoint，因此严格来说，Dense并没有detect的动作。\n",
    "    在某些情况下（如风景类图片），Dense的效果其实不会比FAST 、Harris 、 DoG等其它detector差。\n",
    "    Dense算法虽然简单，但也是其缺点，因为过于简单而产生过多的keypoints，甚至于超过图片中实际的数量，过多的keypoints需要更多的记忆体、储存及运算量。\n",
    "    单纯的Dense无法适用于不同尺寸的图像，因此需在Keypoints上加入不同半径大小的侦测点(Multiple radii)才能应用不同的尺寸大小(scale invariant)。\n",
    "    资源耗用大，因此Dense不适用于realtime及运行于小型装置。\n",
    "    适合用于机器学习的影像分类及基于内容的影像搜索。\n",
    "    Dense分为单一radii及多重radii两种方法，其中后者可适应尺寸变化的情况。\n",
    "\n",
    "\n",
    "#### BRISK\n",
    "\n",
    "    FAST keypoint detectorh的强化，主要是针对尺寸缩放的部份（scale space invariance）。\n",
    "    会先以pyramid方式产生尺寸大小不同的影像，再针对每一层进行FAST运算及取值。\n",
    "    速度快，适用于realtime的环境。\n",
    "    适用于侦测Corners。\n",
    "\n",
    "\n",
    "#### ORB\n",
    "\n",
    "    与BRISK相同，ORB亦是针对FAST的强化，但除了scale space invariance，亦加入了旋转不变性(rotation invariance).。\n",
    "    ORB原理有三大步骤：\n",
    "    Pyramid图像尺寸并进行各尺寸的FAST计算。\n",
    "    使用Harris keypoint detector的方法计算每个keypoint分数），并进行排序，最多仅取500个keypoints，其余则丢弃。\n",
    "    于此第三步中加入旋转不变性，使用「intensity centroid」计算每个keypoint的rotation。\n",
    "    ORB与BRISK相同，继承了FAST运算快速的特性，可适用于realtime分析。\n",
    "    \n",
    "    orb = cv2.ORB()\n",
    "\n",
    "#### opencv 3.3之后不再免费开发SIFT/SURF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征匹配\n",
    "在影像中选取重要的特征点，接着以其为base取得周围的特征（即local features），这些来自不同相片的local features 会通过Feature matching功能来比对是否有相同的物件。\n",
    "使用 OpenCV 中的蛮力（Brute-Force）匹配和 FLANN 匹配\n",
    "\n",
    "蛮力匹配器是很简单的。首先在第一幅图像中选取一个关键点然后依次与第二幅图像的每个关键点进行（描述符）距离测试，最后返回距离最近的关键点。\n",
    "\n",
    "FLANN 是快速最近邻搜索包（Fast_Library_for_Approximate_Nearest_Neighbors）的简称。它是一个对大数据集和高维特征进行最近邻搜索的算法的集合，而且这些算法都已经被优化过了。在面对大数据集时它的效果要好于 BFMatcher。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_show(name,img):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('img/box.png', 0)\n",
    "img2 = cv2.imread('img/box_in_scene.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img1',img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img2',img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opencv 3.3之后不再免费开发SIFT\n",
    "orb = cv2.FastFeatureDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossCheck表示两个特征点要互相匹，例如A中的第i个特征点与B中的第j个特征点最近的，并且B中的第j个特征点到A中的第i个特征点也是 \n",
    "#NORM_L2: 归一化数组的(欧几里德距离)，如果其他特征计算方法需要考虑不同的匹配计算方式\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1对1的匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key=lambda x: x.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None,flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img3',img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k对最佳匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "\n",
    "matches = bf.knnMatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good.append([m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img3',img3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
