## 目标检测
参考
https://github.com/scutan90/DeepLearning-500-questions
https://blog.csdn.net/electech6/article/details/95240278
https://www.cnblogs.com/zyly/p/9651261.html


训练样本总结
https://www.mobibrw.com/2017/7900

### 概述
? 目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。
由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。

?
#### 计算机视觉中关于图像识别有四大类任务：

分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。

定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。

检测-Detection：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。

分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。


#### 目标检测算法分类

1.Two stage目标检测算法（准确度高一些，但是速度慢）
  需要先算法产生目标候选框，也就是目标位置（region proposal，RP），然后再对候选框通过卷积神经网络做分类与回归。
? 
任务：特征提取―>生成RP―>分类/定位回归。

? 常见的two stage目标检测算法有：R-CNN、SPP-Net、Fast R-CNN、Faster R-CNN和R-FCN等。

2.One stage目标检测算法（速度快，但是准确性要低一些）

? 使用一个卷积神经网络CNN直接预测不同目标的类别与位置，不用RP，直接在网络中提取特征来预测物体分类和位置。

? 任务：特征提取―>分类/定位回归。

? 常见的one stage目标检测算法有：OverFeat、YOLOv1、YOLOv2、YOLOv3、SSD和RetinaNet等。

#### 应用
? 目标检测具有巨大的实用价值和应用前景。应用领域包括人脸检测、行人检测、车辆检测、飞机航拍或卫星图像中道路的检测、车载摄像机图像中的障碍物检测、医学影像在的病灶检测等。还有在安防领域中，可以实现比如安全帽、安全带等动态检测，移动侦测、区域入侵检测、物品看护等功能。



### 基于传统图像处理的目标检测（HOG+SVM）
#### 方向梯度直方图HOG(Histogram of Oriented Gradient)
HOG特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子，是与SIFT、SURF、ORB属于同一类型的描述符。
HOG不是基于颜色值而是基于梯度来计算直方图的，它通过计算和统计图像局部区域的梯度方向直方图来构建特征。

#### 1.图片预处理
图片的预处理有很多，这个要根据实际情况来处理是否需要做平滑等操作
为了减少光照因素的影响，降低图像局部的阴影和光照变化所造成的影响，我们首先采用Gamma校正法对输入图像的颜色空间进行标准化(或者说是归一化)。
如果有兴趣可以读一下gamma校正 https://www.cnblogs.com/qiqibaby/p/5325193.html  

#### 2.边缘方向计算
 计算图像每个像素点的梯度、包括方向和大小直方图计算
 
#### 3.直方图计算
将图像划分成小的细胞单元(细胞单元可以是矩形的或者环形的)，比如大小为8×8，然后统计每一个细胞单元的梯度直方图，即可以得到一个细胞单元的描述符，将几个细胞单元组成一个block，
例如2×2个细胞单元组成一个block，将一个block内每个细胞单元的描述符串联起来即可以得到一个block的HOG描述符。

在说到统计一个细胞单元的梯度直方图时，我们一般考虑采用9个bin的直方图来统计这8×8个像素的梯度信息
 ![iamge](img/hoggrade.png)
 
#### 4.对block归一化
由于局部光照的变化，以及前景背景对比度的变化，使得梯度强度的变化范围非常大，这就需要对梯度做局部对比度归一化。
归一化能够进一步对光照、阴影、边缘进行压缩，使得特征向量对光照、阴影和边缘变化具有鲁棒性。

#### 5.样本HOG特征提
最后一步就是对一个样本中所有的块进行HOG特征的手机，并将它们结合成最终的特征向量送入分类器。

那么一个样本可以提取多少个特征呢？之前我们已经说过HOG特征的提取过程：

首先把样本图片分割为若干个像素的单元，然后把梯度方向划分为9个区间，在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，
得到一个9维的特征向量；

每相邻4个单元构成一个块，把一个块内的特征向量串联起来得到一个36维的特征向量；

用块对样本图像进行扫描，扫描步长为一个单元的大小，最后将所有的块的特征串联起来，就得到一个样本的特征向量；
例如：对于128×64的输入图片(后面我所有提到的图像大小指的是h×w)，每个块由2×2个cell组成，每个cell由8×8个像素点组成，每个cell提取9个bin大小的直方图，以1个cell大小为步长，那么水平方向有7个扫描窗口，垂直方向有5个扫描窗口，也就是说，一共有15?7?2?2?9=3780个特征。

#### 图像金字塔
图像金字塔有助于解决不同尺度下的目标检测问题
构建图像金字塔一般包含以下步骤(详细内容可以参考尺度空间理论）：

	获取图像；
	使用任意尺度的参数来调整(缩小)图像的大小；
	平滑图像(使用高斯模糊)；
	如果图像比最小尺度还大，从第一步开会重复这个过程；
如果需要输入图像的不同尺度下检测对象，则函数detectMultiScale()，
该函数有一个比较重要的参数scaleFactor(一般设置为1.3)，表示一个比率：即在每层金字塔中所获得的图像与上一层图像的比率，scaleFactor越小，金字塔的层数就越多，计算就越慢，计算量也会更大，但是计算结果相对更精确。	

#### 滑动窗口
滑动窗口是用在计算机视觉的一种技术，它包括图像中要移动部分(滑动窗口)的检查以及使用图像金字塔对各部分进行检测。这是为了在多尺度下检测对象。

滑动窗口通过扫描较大图像的较小区域来解决定位问题，进而在同一图像的不同尺度下重复扫描。

使用这种方法进行目标检测会出现一个问题：区域重叠，针对区域重叠问题，我们可以利用非极大值抑制，来消除重叠的窗口。	

#### HOG的优点： 

核心思想是所检测的局部物体外形能够被梯度或边缘方向的分布所描述，HOG能较好地捕捉局部形状信息，对几何和光学变化都有很好的不变性； 
HOG是在密集采样的图像块中求取的，在计算得到的HOG特征向量中隐含了该块与检测窗口之间的空间位置关系。
HOG的缺陷： 

很难处理遮挡问题，人体姿势动作幅度过大或物体方向改变也不易检测（这个问题后来在DPM中采用可变形部件模型的方法得到了改善）；
跟SIFT相比，HOG没有选取主方向，也没有旋转梯度方向直方图，因而本身不具有旋转不变性（较大的方向变化），其旋转不变性是通过采用不同旋转方向的训练样本来实现的；
跟SIFT相比，HOG本身不具有尺度不变性，其尺度不变性是通过缩放检测窗口图像的大小来实现的；
此外，由于梯度的性质，HOG对噪点相当敏感，在实际应用中，在block和cell划分之后，对于得到各个区域，有时候还会做一次高斯平滑去除噪点。

#### 实践


### RCNN
https://arxiv.org/abs/1311.2524

![iamge](RCNN.JPG)
? R-CNN其实没有过多的使用“深度学习”思想，而是将“深度学习”和传统的“计算机视觉”的知识相结合

#### Selective Search
Selective Search选择性搜索是用于目标检测的区域提议算法，它计算速度快，具有很高的召回率，
基于颜色，纹理，大小和形状兼容计算相似区域的分层分组。学习更多关于Selective Search https://zhuanlan.zhihu.com/p/27467369




#### 训练步骤

1.提取候选区域，简单来说就是通过一些传统图像处理方法将图像分成很多小尺寸区域，然后根据小尺寸区域的特征合并小尺寸得到大尺寸区域，以实现候选区域的选取。
利用选择性搜索（Selective Search）算法提取所有proposals（大约2000幅images），调整（resize/warp）它们成固定大小，以满足 CNN输入要求（因为全连接层的限制）


2.提取特征向量对于上述获取的候选区域，需进一步使用CNN提取对应的特征向量，选择一个预训练 （pre-trained）神经网络（如AlexNet、VGG）。然后将feature map 保存到本地磁盘。
（需要注意的是 Alexnet 的输入图像大小是 227x227，而通过 Selective Search 产生的候选区域大小不一，
为了与 Alexnet 兼容，R-CNN 采用了非常暴力的手段，那就是无视候选区域的大小和形状，统一变换到 227x227 的尺寸）

4.训练SVM。通过上述卷积神经网络获取候选区域的特征向量，进一步使用SVM进行物体分类，利用feature map 训练SVM来对目标和背景进行分类

5.边框修正。训练将输出一些校正因子的线性回归分类器


### Fast R-CNN
https://arxiv.org/abs/1504.08083

![iamge](img/fastrcnn.jpg)
Fast R-CNN通过CNN直接获取整张图像的特征图，再使用RoI Pooling Layer在特征图上获取对应每个候选框的特征，避免了R-CNN中的对每个候选框串行进行卷积（耗时较长）。

#### 训练步骤
	1.首先还是采用selective search提取2000个候选框RoI
	2.使用一个卷积神经网络对全图进行特征提取
	3.使用一个RoI Pooling Layer在全图特征上摘取每一个RoI对应的特征
	4.分别经过为21和84维的全连接层（并列的，前者是分类输出，后者是回归输出）


#### RoI的具体操作
将region proposal的特征向量划分为目标H×W大小的分块

对每一个分块中做MaxPooling（每个分块中含有多个网格，每个分块获取一个特征值）

将所有输出值组合起来便形成固定大小为H×W的feature map上的box坐标


RoI Pooling的输出

输出是batch个vector，其中batch的值等于RoI的个数，vector的大小为channel * w * h；RoI Pooling的过程就是将一个个大小不同的box矩形框，都映射成大小固定（w * h）的矩形框。


Fast R-CNN的主要贡献：

取代R-CNN的串行特征提取方式，直接采用一个CNN对全图提取特征(这也是为什么需要RoI Pooling的原因)。

用RoI pooling层替换最后一层的max pooling层，同时引入建议框数据，提取相应建议框特征

Fast R-CNN网络末尾采用并行的不同的全连接层，可同时输出分类结果和窗口回归结果，实现了end-to-end的多任务训练【建议框提取除外】，
也不需要额外的特征存储空间【R-CNN中的特征需要保持到本地，来供SVM和Bounding-box regression进行训练】

采用SVD对Fast R-CNN网络末尾并行的全连接层进行分解，减少计算复杂度，加快检测速度。


Fast R-CNN也有缺点，体现在耗时的selective search还是依旧存在。






### Faster R-CNN
https://arxiv.org/abs/1506.01497

![iamge](img/fasterrnn2.png)


#### 算法步骤
1.首先使用共享卷积层为全图提取特征feature maps

2.将得到的feature maps送入RPN，RPN生成待检测框(指定RoI的位置),并对RoI的包围框进行第一次修正

3.RoI Pooling Layer根据RPN的输出在feature map上面选取每个RoI对应的特征，并将维度置为定值

4.使用全连接层(FC Layer)对框进行分类，并且进行目标包围框的第二次修正。


尤其注意的是，Faster R-CNN真正实现了端到端的训练(end-to-end training)。Faster R-CNN最大特色是使用了RPN取代了SS算法来获取RoI，以下对RPN进行分析。


#### RPN
RPN网络用于生成区域候选图像块。该层通过softmax判断锚点(anchors)属于前景(foreground)或者背景(background)，
再利用边界框回归(bounding box regression)修正anchors获得精确的proposals。

##### anchor：
简单地说，RPN依靠一个在共享特征图上滑动的窗口，为每个位置生成9种预先设置好长宽比与面积的目标框(即anchor)。
这9种初始anchor包含三种面积(128×128，256×256，512×512)，每种面积又包含三种长宽比(1:1，1:2，2:1)
![iamge](img/anchor.jpg)


##### 判断前景或背景：
对于所有的anchors，首先需要判断anchor是是否为前景。对于第一个问题，RPN的做法是使用SoftmaxLoss直接训练，在训练的时候排除掉了超越图像边界的anchor；

##### 边框修正：
所以我们希望采用一种方法对候选区域的框进行微调，使得候选区域和实际框更加接近

	首先通过RPN生成约20000个anchor(40×60×9)。
	对20000个anchor进行第一次边框修正，得到修订边框后的proposal。
	对超过图像边界的proposal的边进行clip，使得该proposal不超过图像范围。
	忽略掉长或者宽太小的proposal。
	将所有proposal按照前景分数从高到低排序，选取前12000个proposal。
	使用阈值为0.7的NMS算法排除掉重叠的proposal。
	针对上一步剩下的proposal,选取前2000个proposal进行分类和第二次边框修正。

	
### Mask R-CNN
Mask R-CNN可以分解为如下的3个模块：Faster-RCNN、RoI Align和Mask。算法框架如下：

![iamge](img/maskrnn.jpg)

#### 算法步骤:

首先，输入一幅你想处理的图片，然后进行对应的预处理操作，或者预处理后的图片；

然后，将其输入到一个预训练好的神经网络中（ResNeXt等）获得对应的feature map；

接着，对这个feature map中的每一点设定预定个的RoI，从而获得多个候选RoI；

接着，将这些候选的RoI送入RPN网络进行二值分类（前景或背景）和BB回归，过滤掉一部分候选的ROI；

接着，对这些剩下的RoI进行RoIAlign操作（即先将原图和feature map的pixel对应起来，然后将feature map和固定的feature对应起来）；

最后，对这些RoI进行分类（N类别分类）、BB回归和MASK生成（在每一个ROI里面进行FCN操作）。


Mask R-CNN是一个非常灵活的框架，可以增加不同的分支完成不同的任务，
可以完成目标分类、目标检测、语义分割、实例分割、人体姿势识别等多种任务。



### YOLO
https://arxiv.org/abs/1506.02640

### SSD
https://arxiv.org/abs/1512.02325


### RetinaNet
https://arxiv.org/abs/1708.02002

