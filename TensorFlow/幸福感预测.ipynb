{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "testdata = pd.read_csv('../data/dataannalysis/happiness_test_abbr.csv')\n",
    "traindata = pd.read_csv('../data/dataannalysis/happiness_train_abbr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#异常数据处理\n",
    "traindata = traindata[traindata['happiness'] != -8]\n",
    "traindata = traindata[traindata['depression'] != -8]\n",
    "traindata = traindata[traindata['class'] != -8]\n",
    "traindata = traindata[traindata['health'] != -8]\n",
    "traindata = traindata[traindata['equity'] != -8]\n",
    "traindata = traindata[traindata['family_status'] != -8]\n",
    "traindata = traindata[traindata['health_problem'] != -8]\n",
    "traindata = traindata[traindata['relax'] != -8]\n",
    "traindata = traindata[traindata['learn'] != -8]\n",
    "traindata['view'].replace(-8,3,inplace = True)\n",
    "traindata = traindata[traindata['socialize'] != -8]\n",
    "traindata = traindata[traindata['socialize'] != -1]\n",
    "traindata = traindata[traindata['socialize'] != -2]\n",
    "traindata = traindata[traindata['socialize'] != -3]\n",
    "traindata = traindata[traindata['socialize'] != 50]\n",
    "traindata = traindata[traindata['status_3_before'] != -8]\n",
    "traindata = traindata[traindata['status_peer'] != -8]\n",
    "traindata['inc_ability'].replace(-8,3,inplace = True)\n",
    "\n",
    "\n",
    "#数据重新处理\n",
    "traindata['marital'].replace(2,1,inplace = True)\n",
    "traindata['marital'].replace(3,1,inplace = True)\n",
    "traindata['marital'].replace(4,1,inplace = True)\n",
    "traindata['marital'].replace(7,1,inplace = True)\n",
    "traindata['marital'].replace(6,2,inplace = True)\n",
    "traindata['marital'].replace(5,3,inplace = True)\n",
    "\n",
    "bins = [-100,0,100000,300000,500000,1000000,10000000] \n",
    "traindata['income'] = pd.cut(traindata['income'],bins, labels=['1','2', '3', '4', '5', '6'])\n",
    "\n",
    "\n",
    "\n",
    "avg_income=traindata['family_income']/traindata['family_m']\n",
    "traindata['avg_income'] = avg_income\n",
    "bins = [-100,0,20000,50000,100000,1000000,10000000] \n",
    "traindata['avg_income'] = pd.cut(traindata['avg_income'],bins, labels=['1','2', '3', '4', '5', '6'])\n",
    "\n",
    "testdata['view'].replace(-8,3,inplace = True)\n",
    "testdata['inc_ability'].replace(-8,3,inplace = True)\n",
    "\n",
    "testdata['marital'].replace(2,1,inplace = True)\n",
    "testdata['marital'].replace(3,1,inplace = True)\n",
    "testdata['marital'].replace(4,1,inplace = True)\n",
    "testdata['marital'].replace(7,1,inplace = True)\n",
    "testdata['marital'].replace(6,2,inplace = True)\n",
    "testdata['marital'].replace(5,3,inplace = True)\n",
    "\n",
    "testdata['income'] = pd.cut(testdata['income'],bins, labels=['1','2', '3', '4', '5', '6'])\n",
    "\n",
    "\n",
    "avg_income=testdata['family_income']/testdata['family_m']\n",
    "testdata['avg_income'] = avg_income\n",
    "testdata['avg_income'] = pd.cut(testdata['avg_income'],bins, labels=['1','2', '3', '4', '5', '6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains new labels: ['0']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-37f8455d8c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_income'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_income'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'income'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'income'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y contains new labels: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains new labels: ['0']"
     ]
    }
   ],
   "source": [
    "#traindata['avg_income'].('unknown', inplace=True)\n",
    "traindata['avg_income'] = traindata['avg_income'].cat.add_categories(['0']);\n",
    "traindata['avg_income'].fillna('0', inplace=True)\n",
    "\n",
    "le = sklearn.preprocessing.LabelEncoder() \n",
    "le.fit(['1','2', '3', '4', '5', '6', '0']) \n",
    "traindata['avg_income']  = le.transform(traindata['avg_income'] ) \n",
    "\n",
    "le = sklearn.preprocessing.LabelEncoder() \n",
    "le.fit(['1','2', '3', '4', '5', '6']) \n",
    "traindata['income']  = le.transform(traindata['income'] ) \n",
    "\n",
    "#traindata['avg_income'].('unknown', inplace=True)\n",
    "testdata['avg_income'] = testdata['avg_income'].cat.add_categories(['0']);\n",
    "testdata['avg_income'].fillna('0', inplace=True)\n",
    "\n",
    "\n",
    "testdata['avg_income']  = le.transform(testdata['avg_income'] ) \n",
    "\n",
    "testdata['income']  = le.transform(testdata['income'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatafinal = traindata[['happiness','depression','class','health','equity','family_status','health_problem','relax','learn','view','socialize','status_peer','status_3_before','inc_ability','car','avg_income','edu']]\n",
    "\n",
    "testdatafinal = testdata[['depression','class','health','equity','family_status','health_problem','relax','learn','view','socialize','status_peer','status_3_before','inc_ability','car','avg_income','edu']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4939 train examples\n",
      "1235 validation examples\n",
      "1544 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(traindatafinal, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depression</th>\n",
       "      <th>class</th>\n",
       "      <th>health</th>\n",
       "      <th>equity</th>\n",
       "      <th>family_status</th>\n",
       "      <th>health_problem</th>\n",
       "      <th>relax</th>\n",
       "      <th>learn</th>\n",
       "      <th>view</th>\n",
       "      <th>socialize</th>\n",
       "      <th>status_peer</th>\n",
       "      <th>status_3_before</th>\n",
       "      <th>inc_ability</th>\n",
       "      <th>car</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      depression  class  health  equity  family_status  health_problem  relax  \\\n",
       "1214           3      1       3       4              2               4      4   \n",
       "422            2      3       3       4              3               4      2   \n",
       "4883           4      4       4       3              1               4      1   \n",
       "2932           4      4       3       4              2               4      4   \n",
       "7584           3      5       2       4              3               2      4   \n",
       "\n",
       "      learn  view  socialize  status_peer  status_3_before  inc_ability  car  \\\n",
       "1214      4     4          2            3                2            2    2   \n",
       "422       1     3          1            3                2            3    2   \n",
       "4883      1     3          2            3                2            2    2   \n",
       "2932      1     3          4            3                2            3    2   \n",
       "7584      1     4          1            2                2            2    2   \n",
       "\n",
       "      avg_income  edu  \n",
       "1214           2   10  \n",
       "422            1    4  \n",
       "4883           2    1  \n",
       "2932           2    4  \n",
       "7584           2    1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train.copy()\n",
    "labels = train_x.pop('happiness')\n",
    "train_y = tf.one_hot(labels-1,5)\n",
    "\n",
    "test_x = test.copy()\n",
    "testlabels = test_x.pop('happiness')\n",
    "test_y = tf.one_hot(testlabels-1,5)\n",
    "\n",
    "val_x = train.copy()\n",
    "vallabels = val_x.pop('happiness')\n",
    "val_y = tf.one_hot(vallabels-1,5)\n",
    "\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214    4\n",
       "422     1\n",
       "4883    3\n",
       "2932    4\n",
       "7584    4\n",
       "Name: happiness, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=384, shape=(4939, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_y = tf.one_hot(labels-1,5)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 77        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "#   layers.Flatten(input_shape=(NONE, 28)),\n",
    "  layers.Dense(10,kernel_regularizer= tf.keras.regularizers.l2(0.001), activation='relu', input_shape=[16]),\n",
    "  layers.Dense(7, kernel_regularizer=tf.keras.regularizers.l2(0.001),activation='relu'),\n",
    "  layers.Dense(5, activation='sigmoid')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy','mae', 'mse'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4939 samples, validate on 4939 samples\n",
      "Epoch 1/40\n",
      "4939/4939 [==============================] - 0s 65us/sample - loss: 0.4632 - accuracy: 0.0626 - mae: 0.5894 - mse: 0.4425 - val_loss: 0.4249 - val_accuracy: 0.0624 - val_mae: 0.5649 - val_mse: 0.4047\n",
      "Epoch 2/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.4038 - accuracy: 0.0624 - mae: 0.5487 - mse: 0.3838 - val_loss: 0.3786 - val_accuracy: 0.0624 - val_mae: 0.5274 - val_mse: 0.3589\n",
      "Epoch 3/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.3630 - accuracy: 0.0628 - mae: 0.5122 - mse: 0.3435 - val_loss: 0.3450 - val_accuracy: 0.0628 - val_mae: 0.4936 - val_mse: 0.3258\n",
      "Epoch 4/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.3344 - accuracy: 0.0630 - mae: 0.4816 - mse: 0.3153 - val_loss: 0.3218 - val_accuracy: 0.0664 - val_mae: 0.4673 - val_mse: 0.3031\n",
      "Epoch 5/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.3133 - accuracy: 0.0739 - mae: 0.4584 - mse: 0.2947 - val_loss: 0.3021 - val_accuracy: 0.0887 - val_mae: 0.4500 - val_mse: 0.2839\n",
      "Epoch 6/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.2930 - accuracy: 0.1223 - mae: 0.4442 - mse: 0.2750 - val_loss: 0.2807 - val_accuracy: 0.1849 - val_mae: 0.4368 - val_mse: 0.2630\n",
      "Epoch 7/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.2708 - accuracy: 0.2687 - mae: 0.4340 - mse: 0.2533 - val_loss: 0.2583 - val_accuracy: 0.3655 - val_mae: 0.4303 - val_mse: 0.2410\n",
      "Epoch 8/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.2497 - accuracy: 0.4128 - mae: 0.4267 - mse: 0.2327 - val_loss: 0.2390 - val_accuracy: 0.4645 - val_mae: 0.4197 - val_mse: 0.2222\n",
      "Epoch 9/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.2310 - accuracy: 0.4894 - mae: 0.4121 - mse: 0.2143 - val_loss: 0.2202 - val_accuracy: 0.5183 - val_mae: 0.4018 - val_mse: 0.2038\n",
      "Epoch 10/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.2118 - accuracy: 0.5367 - mae: 0.3911 - mse: 0.1955 - val_loss: 0.2011 - val_accuracy: 0.5564 - val_mae: 0.3759 - val_mse: 0.1850\n",
      "Epoch 11/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1933 - accuracy: 0.5704 - mae: 0.3659 - mse: 0.1775 - val_loss: 0.1836 - val_accuracy: 0.5859 - val_mae: 0.3514 - val_mse: 0.1680\n",
      "Epoch 12/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1771 - accuracy: 0.5912 - mae: 0.3407 - mse: 0.1616 - val_loss: 0.1692 - val_accuracy: 0.5961 - val_mae: 0.3276 - val_mse: 0.1539\n",
      "Epoch 13/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1641 - accuracy: 0.5985 - mae: 0.3170 - mse: 0.1490 - val_loss: 0.1580 - val_accuracy: 0.6009 - val_mae: 0.3043 - val_mse: 0.1432\n",
      "Epoch 14/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1543 - accuracy: 0.6013 - mae: 0.2956 - mse: 0.1396 - val_loss: 0.1499 - val_accuracy: 0.6023 - val_mae: 0.2835 - val_mse: 0.1355\n",
      "Epoch 15/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1472 - accuracy: 0.6023 - mae: 0.2768 - mse: 0.1330 - val_loss: 0.1441 - val_accuracy: 0.6023 - val_mae: 0.2707 - val_mse: 0.1301\n",
      "Epoch 16/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1421 - accuracy: 0.6036 - mae: 0.2641 - mse: 0.1282 - val_loss: 0.1398 - val_accuracy: 0.6038 - val_mae: 0.2569 - val_mse: 0.1261\n",
      "Epoch 17/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1383 - accuracy: 0.6038 - mae: 0.2530 - mse: 0.1249 - val_loss: 0.1366 - val_accuracy: 0.6040 - val_mae: 0.2501 - val_mse: 0.1234\n",
      "Epoch 18/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1355 - accuracy: 0.6040 - mae: 0.2470 - mse: 0.1226 - val_loss: 0.1343 - val_accuracy: 0.6040 - val_mae: 0.2425 - val_mse: 0.1215\n",
      "Epoch 19/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1335 - accuracy: 0.6040 - mae: 0.2414 - mse: 0.1210 - val_loss: 0.1325 - val_accuracy: 0.6042 - val_mae: 0.2369 - val_mse: 0.1202\n",
      "Epoch 20/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1318 - accuracy: 0.6042 - mae: 0.2376 - mse: 0.1198 - val_loss: 0.1310 - val_accuracy: 0.6042 - val_mae: 0.2361 - val_mse: 0.1191\n",
      "Epoch 21/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1305 - accuracy: 0.6042 - mae: 0.2361 - mse: 0.1189 - val_loss: 0.1297 - val_accuracy: 0.6042 - val_mae: 0.2336 - val_mse: 0.1184\n",
      "Epoch 22/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1293 - accuracy: 0.6040 - mae: 0.2331 - mse: 0.1181 - val_loss: 0.1287 - val_accuracy: 0.6040 - val_mae: 0.2354 - val_mse: 0.1178\n",
      "Epoch 23/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1283 - accuracy: 0.6040 - mae: 0.2336 - mse: 0.1175 - val_loss: 0.1277 - val_accuracy: 0.6040 - val_mae: 0.2324 - val_mse: 0.1172\n",
      "Epoch 24/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1273 - accuracy: 0.6040 - mae: 0.2325 - mse: 0.1170 - val_loss: 0.1268 - val_accuracy: 0.6040 - val_mae: 0.2301 - val_mse: 0.1167\n",
      "Epoch 25/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1265 - accuracy: 0.6040 - mae: 0.2310 - mse: 0.1166 - val_loss: 0.1260 - val_accuracy: 0.6040 - val_mae: 0.2320 - val_mse: 0.1164\n",
      "Epoch 26/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1258 - accuracy: 0.6040 - mae: 0.2312 - mse: 0.1163 - val_loss: 0.1252 - val_accuracy: 0.6040 - val_mae: 0.2327 - val_mse: 0.1160\n",
      "Epoch 27/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1250 - accuracy: 0.6040 - mae: 0.2313 - mse: 0.1159 - val_loss: 0.1245 - val_accuracy: 0.6040 - val_mae: 0.2317 - val_mse: 0.1156\n",
      "Epoch 28/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1243 - accuracy: 0.6040 - mae: 0.2315 - mse: 0.1155 - val_loss: 0.1240 - val_accuracy: 0.6042 - val_mae: 0.2262 - val_mse: 0.1154\n",
      "Epoch 29/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1237 - accuracy: 0.6042 - mae: 0.2292 - mse: 0.1153 - val_loss: 0.1233 - val_accuracy: 0.6042 - val_mae: 0.2299 - val_mse: 0.1150\n",
      "Epoch 30/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1231 - accuracy: 0.6042 - mae: 0.2298 - mse: 0.1150 - val_loss: 0.1228 - val_accuracy: 0.6040 - val_mae: 0.2332 - val_mse: 0.1148\n",
      "Epoch 31/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1227 - accuracy: 0.6040 - mae: 0.2305 - mse: 0.1149 - val_loss: 0.1222 - val_accuracy: 0.6040 - val_mae: 0.2312 - val_mse: 0.1145\n",
      "Epoch 32/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1220 - accuracy: 0.6042 - mae: 0.2301 - mse: 0.1144 - val_loss: 0.1217 - val_accuracy: 0.6044 - val_mae: 0.2288 - val_mse: 0.1143\n",
      "Epoch 33/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1216 - accuracy: 0.6042 - mae: 0.2293 - mse: 0.1143 - val_loss: 0.1212 - val_accuracy: 0.6044 - val_mae: 0.2312 - val_mse: 0.1140\n",
      "Epoch 34/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1210 - accuracy: 0.6044 - mae: 0.2305 - mse: 0.1140 - val_loss: 0.1208 - val_accuracy: 0.6042 - val_mae: 0.2279 - val_mse: 0.1139\n",
      "Epoch 35/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1206 - accuracy: 0.6044 - mae: 0.2287 - mse: 0.1138 - val_loss: 0.1203 - val_accuracy: 0.6044 - val_mae: 0.2300 - val_mse: 0.1136\n",
      "Epoch 36/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1202 - accuracy: 0.6044 - mae: 0.2299 - mse: 0.1136 - val_loss: 0.1200 - val_accuracy: 0.6044 - val_mae: 0.2274 - val_mse: 0.1135\n",
      "Epoch 37/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1197 - accuracy: 0.6044 - mae: 0.2281 - mse: 0.1133 - val_loss: 0.1196 - val_accuracy: 0.6044 - val_mae: 0.2325 - val_mse: 0.1133\n",
      "Epoch 38/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1193 - accuracy: 0.6044 - mae: 0.2310 - mse: 0.1131 - val_loss: 0.1193 - val_accuracy: 0.6044 - val_mae: 0.2254 - val_mse: 0.1131\n",
      "Epoch 39/40\n",
      "4939/4939 [==============================] - 0s 5us/sample - loss: 0.1191 - accuracy: 0.6044 - mae: 0.2289 - mse: 0.1130 - val_loss: 0.1188 - val_accuracy: 0.6044 - val_mae: 0.2262 - val_mse: 0.1129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40\n",
      "4939/4939 [==============================] - 0s 6us/sample - loss: 0.1187 - accuracy: 0.6044 - mae: 0.2288 - mse: 0.1129 - val_loss: 0.1185 - val_accuracy: 0.6044 - val_mae: 0.2274 - val_mse: 0.1127\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,\n",
    "                    train_y,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(val_x, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544/1544 [==============================] - 0s 19us/sample - loss: 0.1158 - accuracy: 0.6192 - mae: 0.2245 - mse: 0.1101\n",
      "[0.11584633480699569, 0.61917096, 0.22452824, 0.11007025]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188ce7ca3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['mae']\n",
    "val_acc = history_dict['val_mae']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= model.predict(testdatafinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01722544, 0.08192572, 0.16030249, 0.60254866, 0.2208769 ],\n",
       "       [0.01185894, 0.13214874, 0.0903784 , 0.5036901 , 0.11763519],\n",
       "       [0.03937125, 0.3213198 , 0.1091035 , 0.3981722 , 0.11493742],\n",
       "       ...,\n",
       "       [0.01726073, 0.06923667, 0.17752752, 0.62862074, 0.2493692 ],\n",
       "       [0.01052359, 0.07797799, 0.11790338, 0.5852132 , 0.16776866],\n",
       "       [0.00428686, 0.0218471 , 0.13751245, 0.72282267, 0.23971036]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
